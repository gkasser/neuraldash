{
    "Input": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": false,
        "params": [
            {
                "type": "tuple",
                "name": "shape",
                "doc": "A shape tuple (integers), not including the batch size. For instance, shape=(32,) indicates that the expected input will be batches of 32-dimensional vectors. Elements of this tuple can be None; 'None' elements represent dimensions where the shape is not known."
            }
        ]
    },
    "Output": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": false,
        "params": []
    },
    "AbstractRNNCell": {
        "multipleInputs": false,
        "doc": "Abstract object representing an RNN cell\n",
        "altersShape": true,
        "params": []
    },
    "Activation": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "Any",
                "name": "activation",
                "doc": "Activation function, such as `tf.nn.relu`, or string name of built-in activation function, such as \"relu\""
            }
        ]
    },
    "ActivityRegularization": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "float",
                "name": "l1",
                "doc": "L1 regularization factor (positive float)"
            },
            {
                "type": "float",
                "name": "l2",
                "doc": "L2 regularization factor (positive float)"
            }
        ]
    },
    "Add": {
        "multipleInputs": true,
        "doc": "Layer that adds a list of inputs\n",
        "altersShape": true,
        "params": []
    },
    "AdditiveAttention": {
        "multipleInputs": false,
        "doc": "causal: Boolean. Set to `True` for decoder self-attention. Adds a mask such that position `i` cannot attend to positions `j > i`. This prevents the flow of information from the future towards the past Defaults to `False`\ndropout: Float between 0 and 1. Fraction of the units to drop for the attention scores. Defaults to 0.0\n",
        "altersShape": true,
        "params": [
            {
                "type": "bool",
                "name": "use_scale",
                "doc": "If `True`, will create a variable to scale the attention scores"
            }
        ]
    },
    "AlphaDropout": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "float",
                "name": "rate",
                "doc": "float, drop probability (as with `Dropout`) The multiplicative noise will have standard deviation `sqrt(rate / (1 - rate))`"
            },
            {
                "type": "Any",
                "name": "noise_shape",
                "doc": "Any"
            },
            {
                "type": "int",
                "name": "seed",
                "doc": "Integer, optional random seed to enable deterministic behavior"
            }
        ]
    },
    "Attention": {
        "multipleInputs": false,
        "doc": "causal: Boolean. Set to `True` for decoder self-attention. Adds a mask such that position `i` cannot attend to positions `j > i`. This prevents the flow of information from the future towards the past Defaults to `False`\ndropout: Float between 0 and 1. Fraction of the units to drop for the attention scores. Defaults to 0.0\n",
        "altersShape": true,
        "params": [
            {
                "type": "bool",
                "name": "use_scale",
                "doc": "If `True`, will create a scalar variable to scale the attention scores"
            }
        ]
    },
    "Average": {
        "multipleInputs": false,
        "doc": "Layer that averages a list of inputs element-wise\n",
        "altersShape": true,
        "params": []
    },
    "AveragePooling1D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "pool_size",
                "doc": "Integer, size of the average pooling windows"
            },
            {
                "type": "int",
                "name": "strides",
                "doc": "Integer, or None. Factor by which to downscale E.g. 2 will halve the input If None, it will default to `pool_size`"
            },
            {
                "type": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, steps, features)` while `channels_first` corresponds to inputs with shape `(batch, features, steps)`"
            }
        ]
    },
    "AveragePooling2D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "tuple",
                "name": "pool_size",
                "doc": "integer or tuple of 2 integers, factors by which to downscale (vertical, horizontal) `(2, 2)` will halve the input in both spatial dimension If only one integer is specified, the same window length will be used for both dimensions"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "Integer, tuple of 2 integers, or None Strides values If None, it will default to `pool_size`"
            },
            {
                "type": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, height, width, channels)` while `channels_first` corresponds to inputs with shape `(batch, channels, height, width)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            }
        ]
    },
    "AveragePooling3D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "tuple",
                "name": "pool_size",
                "doc": "tuple of 3 integers, factors by which to downscale (dim1, dim2, dim3) `(2, 2, 2)` will halve the size of the 3D input in each dimension"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "tuple of 3 integers, or None. Strides values"
            },
            {
                "type": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)` while `channels_first` corresponds to inputs with shape `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            }
        ]
    },
    "AvgPool1D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "pool_size",
                "doc": "Integer, size of the average pooling windows"
            },
            {
                "type": "int",
                "name": "strides",
                "doc": "Integer, or None. Factor by which to downscale E.g. 2 will halve the input If None, it will default to `pool_size`"
            },
            {
                "type": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, steps, features)` while `channels_first` corresponds to inputs with shape `(batch, features, steps)`"
            }
        ]
    },
    "AvgPool2D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "tuple",
                "name": "pool_size",
                "doc": "integer or tuple of 2 integers, factors by which to downscale (vertical, horizontal) `(2, 2)` will halve the input in both spatial dimension If only one integer is specified, the same window length will be used for both dimensions"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "Integer, tuple of 2 integers, or None Strides values If None, it will default to `pool_size`"
            },
            {
                "type": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, height, width, channels)` while `channels_first` corresponds to inputs with shape `(batch, channels, height, width)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            }
        ]
    },
    "AvgPool3D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "tuple",
                "name": "pool_size",
                "doc": "tuple of 3 integers, factors by which to downscale (dim1, dim2, dim3) `(2, 2, 2)` will halve the size of the 3D input in each dimension"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "tuple of 3 integers, or None. Strides values"
            },
            {
                "type": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)` while `channels_first` corresponds to inputs with shape `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            }
        ]
    },
    "BatchNormalization": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "axis",
                "doc": "Integer, the axis that should be normalized (typically the features axis). For instance, after a `Conv2D` layer with `data_format=\"channels_first\"`, set `axis=1` in `BatchNormalization`"
            },
            {
                "type": "Momentum for the moving average",
                "name": "momentum",
                "doc": "Momentum for the moving average"
            },
            {
                "type": "float",
                "name": "epsilon",
                "doc": "Small float added to variance to avoid dividing by zero"
            },
            {
                "type": "bool",
                "name": "center",
                "doc": "If True, add offset of `beta` to normalized tensor. If False, `beta` is ignored"
            },
            {
                "type": "bool",
                "name": "scale",
                "doc": "If True, multiply by `gamma`. If False, `gamma` is not used. When the next layer is linear (also e.g. `nn.relu`), this can be disabled since the scaling will be done by the next layer"
            },
            {
                "type": "Initializer for the beta weight",
                "name": "beta_initializer",
                "doc": "Initializer for the beta weight"
            },
            {
                "type": "Initializer for the gamma weight",
                "name": "gamma_initializer",
                "doc": "Initializer for the gamma weight"
            },
            {
                "type": "Initializer for the moving mean",
                "name": "moving_mean_initializer",
                "doc": "Initializer for the moving mean"
            },
            {
                "type": "Initializer for the moving variance",
                "name": "moving_variance_initializer",
                "doc": "Initializer for the moving variance"
            },
            {
                "type": "Optional regularizer for the beta weight",
                "name": "beta_regularizer",
                "doc": "Optional regularizer for the beta weight"
            },
            {
                "type": "Optional regularizer for the gamma weight",
                "name": "gamma_regularizer",
                "doc": "Optional regularizer for the gamma weight"
            },
            {
                "type": "Optional constraint for the beta weight",
                "name": "beta_constraint",
                "doc": "Optional constraint for the beta weight"
            },
            {
                "type": "Optional constraint for the gamma weight",
                "name": "gamma_constraint",
                "doc": "Optional constraint for the gamma weight"
            }
        ]
    },
    "Bidirectional": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "`keras.layers.RNN` instance, such as `keras.layers.LSTM` or `keras.layers.GRU`. It could also be a `keras.layers.Layer` instance that meets the following criteria: 1. Be a sequence-processing layer (accepts 3D+ inputs) 2. Have a `go_backwards`, `return_sequences` and `return_state` attribute (with the same semantics as for the `RNN` class) 3. Have an `input_spec` attribute 4. Implement serialization via `get_config()` and `from_config()` Note that the recommended way to create new RNN layers is to write a custom RNN cell and use it with `keras.layers.RNN`, instead of subclassing `keras.layers.Layer` directly - When the `returns_sequences` is true, the output of the masked timestep will be zero regardless of the layer's original `zero_output_for_mask` value",
                "name": "layer",
                "doc": "`keras.layers.RNN` instance, such as `keras.layers.LSTM` or `keras.layers.GRU`. It could also be a `keras.layers.Layer` instance that meets the following criteria: 1. Be a sequence-processing layer (accepts 3D+ inputs) 2. Have a `go_backwards`, `return_sequences` and `return_state` attribute (with the same semantics as for the `RNN` class) 3. Have an `input_spec` attribute 4. Implement serialization via `get_config()` and `from_config()` Note that the recommended way to create new RNN layers is to write a custom RNN cell and use it with `keras.layers.RNN`, instead of subclassing `keras.layers.Layer` directly - When the `returns_sequences` is true, the output of the masked timestep will be zero regardless of the layer's original `zero_output_for_mask` value"
            },
            {
                "type": "Mode by which outputs of the forward and backward RNNs will be combined. One of {'sum', 'mul', 'concat', 'ave', None}. If None, the outputs will not be combined, they will be returned as a list. Default value is 'concat'",
                "name": "merge_mode",
                "doc": "Mode by which outputs of the forward and backward RNNs will be combined. One of {'sum', 'mul', 'concat', 'ave', None}. If None, the outputs will not be combined, they will be returned as a list. Default value is 'concat'"
            },
            {
                "type": "Any",
                "name": "weights",
                "doc": "Any"
            },
            {
                "type": "Optional `keras.layers.RNN`, or `keras.layers.Layer` instance to be used to handle backwards input processing If `backward_layer` is not provided, the layer instance passed as the `layer` argument will be used to generate the backward layer automatically Note that the provided `backward_layer` layer should have properties matching those of the `layer` argument, in particular it should have the same values for `stateful`, `return_states`, `return_sequences`, etc In addition, `backward_layer` and `layer` should have different `go_backwards` argument values A `ValueError` will be raised if these requirements are not met",
                "name": "backward_layer",
                "doc": "Optional `keras.layers.RNN`, or `keras.layers.Layer` instance to be used to handle backwards input processing If `backward_layer` is not provided, the layer instance passed as the `layer` argument will be used to generate the backward layer automatically Note that the provided `backward_layer` layer should have properties matching those of the `layer` argument, in particular it should have the same values for `stateful`, `return_states`, `return_sequences`, etc In addition, `backward_layer` and `layer` should have different `go_backwards` argument values A `ValueError` will be raised if these requirements are not met"
            }
        ]
    },
    "CategoryEncoding": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "The total number of tokens the layer should support. All inputs to the layer must integers in the range `0 <= value < num_tokens`, or an error will be thrown",
                "name": "num_tokens",
                "doc": "The total number of tokens the layer should support. All inputs to the layer must integers in the range `0 <= value < num_tokens`, or an error will be thrown"
            },
            {
                "type": "Specification for the output of the layer Defaults to `\"multi_hot\"`. Values can be `\"one_hot\"`, `\"multi_hot\"` or `\"count\"`, configuring the layer as follows: - `\"one_hot\"`: Encodes each individual element in the input into an array of `num_tokens` size, containing a 1 at the element index. If the last dimension is size 1, will encode on that dimension. If the last dimension is not size 1, will append a new dimension for the encoded output. - `\"multi_hot\"`: Encodes each sample in the input into a single array of `num_tokens` size, containing a 1 for each vocabulary term present in the sample. Treats the last dimension as the sample dimension, if input shape is `(..., sample_length)`, output shape will be `(..., num_tokens)`. - `\"count\"`: Like `\"multi_hot\"`, but the int array contains a count of the number of times the token at that index appeared in the sample For all output modes, currently only output up to rank 2 is supported",
                "name": "output_mode",
                "doc": "Specification for the output of the layer Defaults to `\"multi_hot\"`. Values can be `\"one_hot\"`, `\"multi_hot\"` or `\"count\"`, configuring the layer as follows: - `\"one_hot\"`: Encodes each individual element in the input into an array of `num_tokens` size, containing a 1 at the element index. If the last dimension is size 1, will encode on that dimension. If the last dimension is not size 1, will append a new dimension for the encoded output. - `\"multi_hot\"`: Encodes each sample in the input into a single array of `num_tokens` size, containing a 1 for each vocabulary term present in the sample. Treats the last dimension as the sample dimension, if input shape is `(..., sample_length)`, output shape will be `(..., num_tokens)`. - `\"count\"`: Like `\"multi_hot\"`, but the int array contains a count of the number of times the token at that index appeared in the sample For all output modes, currently only output up to rank 2 is supported"
            },
            {
                "type": "bool",
                "name": "sparse",
                "doc": "Boolean. If true, returns a `SparseTensor` instead of a dense `Tensor`. Defaults to `False`"
            }
        ]
    },
    "CenterCrop": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "height",
                "doc": "Integer, the height of the output shape"
            },
            {
                "type": "int",
                "name": "width",
                "doc": "Integer, the width of the output shape"
            }
        ]
    },
    "Concatenate": {
        "multipleInputs": true,
        "doc": "Layer that concatenates a list of inputs\n",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "axis",
                "doc": "Any"
            }
        ]
    },
    "Conv1D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "filters",
                "doc": "Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution)"
            },
            {
                "type": "tuple",
                "name": "kernel_size",
                "doc": "An integer or tuple/list of a single integer, specifying the length of the 1D convolution window"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "An integer or tuple/list of a single integer, specifying the stride length of the convolution Specifying any stride value != 1 is incompatible with specifying any `dilation_rate` value != 1"
            },
            {
                "type": "One of `\"valid\"`, `\"same\"` or `\"causal\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input `\"causal\"` results in causal (dilated) convolutions, e.g. `output[t]` does not depend on `input[t+1:]`. Useful when modeling temporal data where the model should not violate the temporal order See [WaveNet: A Generative Model for Raw Audio, section 2.1](https://arxiv.org/abs/1609.03499)",
                "name": "padding",
                "doc": "One of `\"valid\"`, `\"same\"` or `\"causal\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input `\"causal\"` results in causal (dilated) convolutions, e.g. `output[t]` does not depend on `input[t+1:]`. Useful when modeling temporal data where the model should not violate the temporal order See [WaveNet: A Generative Model for Raw Audio, section 2.1](https://arxiv.org/abs/1609.03499)"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first`"
            },
            {
                "type": "tuple",
                "name": "dilation_rate",
                "doc": "an integer or tuple/list of a single integer, specifying the dilation rate to use for dilated convolution Currently, specifying any `dilation_rate` value != 1 is incompatible with specifying any `strides` value != 1"
            },
            {
                "type": "int",
                "name": "groups",
                "doc": "A positive integer specifying the number of groups in which the input is split along the channel axis. Each group is convolved separately with `filters / groups` filters. The output is the concatenation of all the `groups` results along the channel axis Input channels and `filters` must both be divisible by `groups`"
            },
            {
                "type": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)",
                "name": "activation",
                "doc": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)"
            },
            {
                "type": "Boolean, whether the layer uses a bias vector",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'"
            },
            {
                "type": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'"
            },
            {
                "type": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)",
                "name": "kernel_regularizer",
                "doc": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the bias vector (see `keras.regularizers`)",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)"
            },
            {
                "type": "Constraint function applied to the kernel matrix (see `keras.constraints`)",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the kernel matrix (see `keras.constraints`)"
            },
            {
                "type": "Constraint function applied to the bias vector (see `keras.constraints`)",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector (see `keras.constraints`)"
            }
        ]
    },
    "Conv1DTranspose": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "filters",
                "doc": "Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution)"
            },
            {
                "type": "int",
                "name": "kernel_size",
                "doc": "An integer length of the 1D convolution window"
            },
            {
                "type": "int",
                "name": "strides",
                "doc": "An integer specifying the stride of the convolution along the time dimension. Specifying a stride value != 1 is incompatible with specifying a `dilation_rate` value != 1. Defaults to 1"
            },
            {
                "type": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "int",
                "name": "output_padding",
                "doc": "An integer specifying the amount of padding along the time dimension of the output tensor The amount of output padding must be lower than the stride If set to `None` (default), the output shape is inferred"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch_size, length, channels)` while `channels_first` corresponds to inputs with shape `(batch_size, channels, length)`"
            },
            {
                "type": "int",
                "name": "dilation_rate",
                "doc": "an integer, specifying the dilation rate to use for dilated convolution Currently, specifying a `dilation_rate` value != 1 is incompatible with specifying a stride value != 1 Also dilation rate larger than 1 is not currently supported"
            },
            {
                "type": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)",
                "name": "activation",
                "doc": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)"
            },
            {
                "type": "Boolean, whether the layer uses a bias vector",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'"
            },
            {
                "type": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'"
            },
            {
                "type": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)",
                "name": "kernel_regularizer",
                "doc": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the bias vector (see `keras.regularizers`)",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)"
            },
            {
                "type": "Constraint function applied to the kernel matrix (see `keras.constraints`)",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the kernel matrix (see `keras.constraints`)"
            },
            {
                "type": "Constraint function applied to the bias vector (see `keras.constraints`)",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector (see `keras.constraints`)"
            }
        ]
    },
    "Conv2D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "filters",
                "doc": "Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution)"
            },
            {
                "type": "tuple",
                "name": "kernel_size",
                "doc": "An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any `dilation_rate` value != 1"
            },
            {
                "type": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input. When `padding=\"same\"` and `strides=1`, the output has the same size as the input",
                "name": "padding",
                "doc": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input. When `padding=\"same\"` and `strides=1`, the output has the same size as the input"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs. `channels_last` corresponds to inputs with shape `(batch_size, height, width, channels)` while `channels_first` corresponds to inputs with shape `(batch_size, channels, height, width)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be `channels_last`"
            },
            {
                "type": "tuple",
                "name": "dilation_rate",
                "doc": "an integer or tuple/list of 2 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any `dilation_rate` value != 1 is incompatible with specifying any stride value != 1"
            },
            {
                "type": "int",
                "name": "groups",
                "doc": "A positive integer specifying the number of groups in which the input is split along the channel axis. Each group is convolved separately with `filters / groups` filters. The output is the concatenation of all the `groups` results along the channel axis. Input channels and `filters` must both be divisible by `groups`"
            },
            {
                "type": "Activation function to use. If you don't specify anything, no activation is applied (see `keras.activations`)",
                "name": "activation",
                "doc": "Activation function to use. If you don't specify anything, no activation is applied (see `keras.activations`)"
            },
            {
                "type": "Boolean, whether the layer uses a bias vector",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'"
            },
            {
                "type": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'"
            },
            {
                "type": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)",
                "name": "kernel_regularizer",
                "doc": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the bias vector (see `keras.regularizers`)",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)"
            },
            {
                "type": "Constraint function applied to the kernel matrix (see `keras.constraints`)",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the kernel matrix (see `keras.constraints`)"
            },
            {
                "type": "Constraint function applied to the bias vector (see `keras.constraints`)",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector (see `keras.constraints`)"
            }
        ]
    },
    "Conv2DTranspose": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "filters",
                "doc": "Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution)"
            },
            {
                "type": "tuple",
                "name": "kernel_size",
                "doc": "An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window Can be a single integer to specify the same value for all spatial dimensions"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width Can be a single integer to specify the same value for all spatial dimensions Specifying any stride value != 1 is incompatible with specifying any `dilation_rate` value != 1"
            },
            {
                "type": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "tuple",
                "name": "output_padding",
                "doc": "An integer or tuple/list of 2 integers, specifying the amount of padding along the height and width of the output tensor Can be a single integer to specify the same value for all spatial dimensions The amount of output padding along a given dimension must be lower than the stride along that same dimension If set to `None` (default), the output shape is inferred"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch_size, height, width, channels)` while `channels_first` corresponds to inputs with shape `(batch_size, channels, height, width)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "tuple",
                "name": "dilation_rate",
                "doc": "an integer or tuple/list of 2 integers, specifying the dilation rate to use for dilated convolution Can be a single integer to specify the same value for all spatial dimensions Currently, specifying any `dilation_rate` value != 1 is incompatible with specifying any stride value != 1"
            },
            {
                "type": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)",
                "name": "activation",
                "doc": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)"
            },
            {
                "type": "Boolean, whether the layer uses a bias vector",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'"
            },
            {
                "type": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'"
            },
            {
                "type": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)",
                "name": "kernel_regularizer",
                "doc": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the bias vector (see `keras.regularizers`)",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)"
            },
            {
                "type": "Constraint function applied to the kernel matrix (see `keras.constraints`)",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the kernel matrix (see `keras.constraints`)"
            },
            {
                "type": "Constraint function applied to the bias vector (see `keras.constraints`)",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector (see `keras.constraints`)"
            }
        ]
    },
    "Conv3D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "filters",
                "doc": "Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution)"
            },
            {
                "type": "tuple",
                "name": "kernel_size",
                "doc": "An integer or tuple/list of 3 integers, specifying the depth, height and width of the 3D convolution window. Can be a single integer to specify the same value for all spatial dimensions"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "An integer or tuple/list of 3 integers, specifying the strides of the convolution along each spatial dimension. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any `dilation_rate` value != 1"
            },
            {
                "type": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs. `channels_last` corresponds to inputs with shape `batch_shape + (spatial_dim1, spatial_dim2, spatial_dim3, channels)` while `channels_first` corresponds to inputs with shape `batch_shape + (channels, spatial_dim1, spatial_dim2, spatial_dim3)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "tuple",
                "name": "dilation_rate",
                "doc": "an integer or tuple/list of 3 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any `dilation_rate` value != 1 is incompatible with specifying any stride value != 1"
            },
            {
                "type": "int",
                "name": "groups",
                "doc": "A positive integer specifying the number of groups in which the input is split along the channel axis. Each group is convolved separately with `filters / groups` filters. The output is the concatenation of all the `groups` results along the channel axis. Input channels and `filters` must both be divisible by `groups`"
            },
            {
                "type": "Activation function to use. If you don't specify anything, no activation is applied (see `keras.activations`)",
                "name": "activation",
                "doc": "Activation function to use. If you don't specify anything, no activation is applied (see `keras.activations`)"
            },
            {
                "type": "Boolean, whether the layer uses a bias vector",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'"
            },
            {
                "type": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'"
            },
            {
                "type": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)",
                "name": "kernel_regularizer",
                "doc": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the bias vector (see `keras.regularizers`)",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)"
            },
            {
                "type": "Constraint function applied to the kernel matrix (see `keras.constraints`)",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the kernel matrix (see `keras.constraints`)"
            },
            {
                "type": "Constraint function applied to the bias vector (see `keras.constraints`)",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector (see `keras.constraints`)"
            }
        ]
    },
    "Conv3DTranspose": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "filters",
                "doc": "Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution)"
            },
            {
                "type": "tuple",
                "name": "kernel_size",
                "doc": "An integer or tuple/list of 3 integers, specifying the depth, height and width of the 3D convolution window Can be a single integer to specify the same value for all spatial dimensions"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "An integer or tuple/list of 3 integers, specifying the strides of the convolution along the depth, height and width Can be a single integer to specify the same value for all spatial dimensions Specifying any stride value != 1 is incompatible with specifying any `dilation_rate` value != 1"
            },
            {
                "type": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "tuple",
                "name": "output_padding",
                "doc": "An integer or tuple/list of 3 integers, specifying the amount of padding along the depth, height, and width Can be a single integer to specify the same value for all spatial dimensions The amount of output padding along a given dimension must be lower than the stride along that same dimension If set to `None` (default), the output shape is inferred"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch_size, depth, height, width, channels)` while `channels_first` corresponds to inputs with shape `(batch_size, channels, depth, height, width)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "tuple",
                "name": "dilation_rate",
                "doc": "an integer or tuple/list of 3 integers, specifying the dilation rate to use for dilated convolution Can be a single integer to specify the same value for all spatial dimensions Currently, specifying any `dilation_rate` value != 1 is incompatible with specifying any stride value != 1"
            },
            {
                "type": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)",
                "name": "activation",
                "doc": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)"
            },
            {
                "type": "Boolean, whether the layer uses a bias vector",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'"
            },
            {
                "type": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'"
            },
            {
                "type": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)",
                "name": "kernel_regularizer",
                "doc": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the bias vector (see `keras.regularizers`)",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)"
            },
            {
                "type": "Constraint function applied to the kernel matrix (see `keras.constraints`)",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the kernel matrix (see `keras.constraints`)"
            },
            {
                "type": "Constraint function applied to the bias vector (see `keras.constraints`)",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector (see `keras.constraints`)"
            }
        ]
    },
    "ConvLSTM1D": {
        "multipleInputs": false,
        "doc": "Call arguments: inputs: A 4D tensor\nmask: Binary tensor of shape `(samples, timesteps)` indicating whether a given timestep should be masked\ntraining: Python boolean indicating whether the layer should behave in training mode or in inference mode. This argument is passed to the cell when calling it. This is only relevant if `dropout` or `recurrent_dropout` are set\ninitial_state: List of initial state tensors to be passed to the first call of the cell\nInput shape: - If data_format='channels_first' 4D tensor with shape: `(samples, time, channels, rows)` - If data_format='channels_last' 4D tensor with shape: `(samples, time, rows, channels)` Output shape: - If `return_state`: a list of tensors. The first tensor is the output. The remaining tensors are the last states, each 3D tensor with shape: `(samples, filters, new_rows)` if data_format='channels_first' or shape: `(samples, new_rows, filters)` if data_format='channels_last'. `rows` values might have changed due to padding\n- If `return_sequences`: 4D tensor with shape: `(samples, timesteps, filters, new_rows)` if data_format='channels_first' or shape: `(samples, timesteps, new_rows, filters)` if data_format='channels_last'\n- Else, 3D tensor with shape: `(samples, filters, new_rows)` if data_format='channels_first' or shape: `(samples, new_rows, filters)` if data_format='channels_last'\n",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "filters",
                "doc": "Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution)"
            },
            {
                "type": "tuple",
                "name": "kernel_size",
                "doc": "An integer or tuple/list of n integers, specifying the dimensions of the convolution window"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "An integer or tuple/list of n integers, specifying the strides of the convolution. Specifying any stride value != 1 is incompatible with specifying any `dilation_rate` value != 1"
            },
            {
                "type": "One of `\"valid\"` or `\"same\"` (case-insensitive). `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "One of `\"valid\"` or `\"same\"` (case-insensitive). `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs. `channels_last` corresponds to inputs with shape `(batch, time, ..., channels)` while `channels_first` corresponds to inputs with shape `(batch, time, channels, ...)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "tuple",
                "name": "dilation_rate",
                "doc": "An integer or tuple/list of n integers, specifying the dilation rate to use for dilated convolution. Currently, specifying any `dilation_rate` value != 1 is incompatible with specifying any `strides` value != 1"
            },
            {
                "type": "Activation function to use. By default hyperbolic tangent activation function is applied (`tanh(x)`)",
                "name": "activation",
                "doc": "Activation function to use. By default hyperbolic tangent activation function is applied (`tanh(x)`)"
            },
            {
                "type": "Activation function to use for the recurrent step",
                "name": "recurrent_activation",
                "doc": "Activation function to use for the recurrent step"
            },
            {
                "type": "Boolean, whether the layer uses a bias vector",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs"
            },
            {
                "type": "Initializer for the `recurrent_kernel` weights matrix, used for the linear transformation of the recurrent state",
                "name": "recurrent_initializer",
                "doc": "Initializer for the `recurrent_kernel` weights matrix, used for the linear transformation of the recurrent state"
            },
            {
                "type": "Initializer for the bias vector",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector"
            },
            {
                "type": "bool",
                "name": "unit_forget_bias",
                "doc": "Boolean. If True, add 1 to the bias of the forget gate at initialization. Use in combination with `bias_initializer=\"zeros\"`. This is recommended in [Jozefowicz et al., 2015]( http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf) kernel_regularizer: Regularizer function applied to the `kernel` weights matrix"
            },
            {
                "type": "Any",
                "name": "kernel_regularizer",
                "doc": "Any"
            },
            {
                "type": "Regularizer function applied to the `recurrent_kernel` weights matrix",
                "name": "recurrent_regularizer",
                "doc": "Regularizer function applied to the `recurrent_kernel` weights matrix"
            },
            {
                "type": "Regularizer function applied to the bias vector",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector"
            },
            {
                "type": "Regularizer function applied to",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to"
            },
            {
                "type": "Constraint function applied to the `kernel` weights matrix",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the `kernel` weights matrix"
            },
            {
                "type": "Constraint function applied to the `recurrent_kernel` weights matrix",
                "name": "recurrent_constraint",
                "doc": "Constraint function applied to the `recurrent_kernel` weights matrix"
            },
            {
                "type": "Constraint function applied to the bias vector",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector"
            },
            {
                "type": "bool",
                "name": "return_sequences",
                "doc": "Boolean. Whether to return the last output in the output sequence, or the full sequence. (default False) return_state: Boolean Whether to return the last state in addition to the output. (default False) go_backwards: Boolean (default False). If True, process the input sequence backwards"
            },
            {
                "type": "Any",
                "name": "return_state",
                "doc": "Any"
            },
            {
                "type": "Any",
                "name": "go_backwards",
                "doc": "Any"
            },
            {
                "type": "bool",
                "name": "stateful",
                "doc": "Boolean (default False). If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch"
            },
            {
                "type": "float",
                "name": "dropout",
                "doc": "Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs"
            },
            {
                "type": "float",
                "name": "recurrent_dropout",
                "doc": "Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state"
            }
        ]
    },
    "ConvLSTM2D": {
        "multipleInputs": false,
        "doc": "Call arguments: inputs: A 5D tensor\nmask: Binary tensor of shape `(samples, timesteps)` indicating whether a given timestep should be masked\ntraining: Python boolean indicating whether the layer should behave in training mode or in inference mode. This argument is passed to the cell when calling it. This is only relevant if `dropout` or `recurrent_dropout` are set\ninitial_state: List of initial state tensors to be passed to the first call of the cell\nInput shape: - If data_format='channels_first' 5D tensor with shape: `(samples, time, channels, rows, cols)` - If data_format='channels_last' 5D tensor with shape: `(samples, time, rows, cols, channels)` Output shape: - If `return_state`: a list of tensors. The first tensor is the output. The remaining tensors are the last states, each 4D tensor with shape: `(samples, filters, new_rows, new_cols)` if data_format='channels_first' or shape: `(samples, new_rows, new_cols, filters)` if data_format='channels_last'. `rows` and `cols` values might have changed due to padding\n- If `return_sequences`: 5D tensor with shape: `(samples, timesteps, filters, new_rows, new_cols)` if data_format='channels_first' or shape: `(samples, timesteps, new_rows, new_cols, filters)` if data_format='channels_last'\n- Else, 4D tensor with shape: `(samples, filters, new_rows, new_cols)` if data_format='channels_first' or shape: `(samples, new_rows, new_cols, filters)` if data_format='channels_last'\n",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "filters",
                "doc": "Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution)"
            },
            {
                "type": "tuple",
                "name": "kernel_size",
                "doc": "An integer or tuple/list of n integers, specifying the dimensions of the convolution window"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "An integer or tuple/list of n integers, specifying the strides of the convolution. Specifying any stride value != 1 is incompatible with specifying any `dilation_rate` value != 1"
            },
            {
                "type": "One of `\"valid\"` or `\"same\"` (case-insensitive). `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "One of `\"valid\"` or `\"same\"` (case-insensitive). `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs. `channels_last` corresponds to inputs with shape `(batch, time, ..., channels)` while `channels_first` corresponds to inputs with shape `(batch, time, channels, ...)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "tuple",
                "name": "dilation_rate",
                "doc": "An integer or tuple/list of n integers, specifying the dilation rate to use for dilated convolution. Currently, specifying any `dilation_rate` value != 1 is incompatible with specifying any `strides` value != 1"
            },
            {
                "type": "Activation function to use. By default hyperbolic tangent activation function is applied (`tanh(x)`)",
                "name": "activation",
                "doc": "Activation function to use. By default hyperbolic tangent activation function is applied (`tanh(x)`)"
            },
            {
                "type": "Activation function to use for the recurrent step",
                "name": "recurrent_activation",
                "doc": "Activation function to use for the recurrent step"
            },
            {
                "type": "Boolean, whether the layer uses a bias vector",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs"
            },
            {
                "type": "Initializer for the `recurrent_kernel` weights matrix, used for the linear transformation of the recurrent state",
                "name": "recurrent_initializer",
                "doc": "Initializer for the `recurrent_kernel` weights matrix, used for the linear transformation of the recurrent state"
            },
            {
                "type": "Initializer for the bias vector",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector"
            },
            {
                "type": "bool",
                "name": "unit_forget_bias",
                "doc": "Boolean. If True, add 1 to the bias of the forget gate at initialization. Use in combination with `bias_initializer=\"zeros\"`. This is recommended in [Jozefowicz et al., 2015]( http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf) kernel_regularizer: Regularizer function applied to the `kernel` weights matrix"
            },
            {
                "type": "Any",
                "name": "kernel_regularizer",
                "doc": "Any"
            },
            {
                "type": "Regularizer function applied to the `recurrent_kernel` weights matrix",
                "name": "recurrent_regularizer",
                "doc": "Regularizer function applied to the `recurrent_kernel` weights matrix"
            },
            {
                "type": "Regularizer function applied to the bias vector",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector"
            },
            {
                "type": "Regularizer function applied to",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to"
            },
            {
                "type": "Constraint function applied to the `kernel` weights matrix",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the `kernel` weights matrix"
            },
            {
                "type": "Constraint function applied to the `recurrent_kernel` weights matrix",
                "name": "recurrent_constraint",
                "doc": "Constraint function applied to the `recurrent_kernel` weights matrix"
            },
            {
                "type": "Constraint function applied to the bias vector",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector"
            },
            {
                "type": "bool",
                "name": "return_sequences",
                "doc": "Boolean. Whether to return the last output in the output sequence, or the full sequence. (default False) return_state: Boolean Whether to return the last state in addition to the output. (default False) go_backwards: Boolean (default False). If True, process the input sequence backwards"
            },
            {
                "type": "Any",
                "name": "return_state",
                "doc": "Any"
            },
            {
                "type": "Any",
                "name": "go_backwards",
                "doc": "Any"
            },
            {
                "type": "bool",
                "name": "stateful",
                "doc": "Boolean (default False). If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch"
            },
            {
                "type": "float",
                "name": "dropout",
                "doc": "Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs"
            },
            {
                "type": "float",
                "name": "recurrent_dropout",
                "doc": "Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state"
            }
        ]
    },
    "ConvLSTM3D": {
        "multipleInputs": false,
        "doc": "Call arguments: inputs: A 6D tensor\nmask: Binary tensor of shape `(samples, timesteps)` indicating whether a given timestep should be masked\ntraining: Python boolean indicating whether the layer should behave in training mode or in inference mode. This argument is passed to the cell when calling it. This is only relevant if `dropout` or `recurrent_dropout` are set\ninitial_state: List of initial state tensors to be passed to the first call of the cell\nInput shape: - If data_format='channels_first' 6D tensor with shape: `(samples, time, channels, rows, cols, depth)` - If data_format='channels_last' 5D tensor with shape: `(samples, time, rows, cols, depth, channels)` Output shape: - If `return_state`: a list of tensors. The first tensor is the output. The remaining tensors are the last states, each 5D tensor with shape: `(samples, filters, new_rows, new_cols, new_depth)` if data_format='channels_first' or shape: `(samples, new_rows, new_cols, new_depth, filters)` if data_format='channels_last'. `rows`, `cols`, and `depth` values might have changed due to padding\n- If `return_sequences`: 6D tensor with shape: `(samples, timesteps, filters, new_rows, new_cols, new_depth)` if data_format='channels_first' or shape: `(samples, timesteps, new_rows, new_cols, new_depth, filters)` if data_format='channels_last'\n- Else, 5D tensor with shape: `(samples, filters, new_rows, new_cols, new_depth)` if data_format='channels_first' or shape: `(samples, new_rows, new_cols, new_depth, filters)` if data_format='channels_last'\n",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "filters",
                "doc": "Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution)"
            },
            {
                "type": "tuple",
                "name": "kernel_size",
                "doc": "An integer or tuple/list of n integers, specifying the dimensions of the convolution window"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "An integer or tuple/list of n integers, specifying the strides of the convolution. Specifying any stride value != 1 is incompatible with specifying any `dilation_rate` value != 1"
            },
            {
                "type": "One of `\"valid\"` or `\"same\"` (case-insensitive). `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "One of `\"valid\"` or `\"same\"` (case-insensitive). `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs. `channels_last` corresponds to inputs with shape `(batch, time, ..., channels)` while `channels_first` corresponds to inputs with shape `(batch, time, channels, ...)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "tuple",
                "name": "dilation_rate",
                "doc": "An integer or tuple/list of n integers, specifying the dilation rate to use for dilated convolution. Currently, specifying any `dilation_rate` value != 1 is incompatible with specifying any `strides` value != 1"
            },
            {
                "type": "Activation function to use. By default hyperbolic tangent activation function is applied (`tanh(x)`)",
                "name": "activation",
                "doc": "Activation function to use. By default hyperbolic tangent activation function is applied (`tanh(x)`)"
            },
            {
                "type": "Activation function to use for the recurrent step",
                "name": "recurrent_activation",
                "doc": "Activation function to use for the recurrent step"
            },
            {
                "type": "Boolean, whether the layer uses a bias vector",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs"
            },
            {
                "type": "Initializer for the `recurrent_kernel` weights matrix, used for the linear transformation of the recurrent state",
                "name": "recurrent_initializer",
                "doc": "Initializer for the `recurrent_kernel` weights matrix, used for the linear transformation of the recurrent state"
            },
            {
                "type": "Initializer for the bias vector",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector"
            },
            {
                "type": "bool",
                "name": "unit_forget_bias",
                "doc": "Boolean. If True, add 1 to the bias of the forget gate at initialization. Use in combination with `bias_initializer=\"zeros\"`. This is recommended in [Jozefowicz et al., 2015]( http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf) kernel_regularizer: Regularizer function applied to the `kernel` weights matrix"
            },
            {
                "type": "Any",
                "name": "kernel_regularizer",
                "doc": "Any"
            },
            {
                "type": "Regularizer function applied to the `recurrent_kernel` weights matrix",
                "name": "recurrent_regularizer",
                "doc": "Regularizer function applied to the `recurrent_kernel` weights matrix"
            },
            {
                "type": "Regularizer function applied to the bias vector",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector"
            },
            {
                "type": "Regularizer function applied to",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to"
            },
            {
                "type": "Constraint function applied to the `kernel` weights matrix",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the `kernel` weights matrix"
            },
            {
                "type": "Constraint function applied to the `recurrent_kernel` weights matrix",
                "name": "recurrent_constraint",
                "doc": "Constraint function applied to the `recurrent_kernel` weights matrix"
            },
            {
                "type": "Constraint function applied to the bias vector",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector"
            },
            {
                "type": "bool",
                "name": "return_sequences",
                "doc": "Boolean. Whether to return the last output in the output sequence, or the full sequence. (default False) return_state: Boolean Whether to return the last state in addition to the output. (default False) go_backwards: Boolean (default False). If True, process the input sequence backwards"
            },
            {
                "type": "Any",
                "name": "return_state",
                "doc": "Any"
            },
            {
                "type": "Any",
                "name": "go_backwards",
                "doc": "Any"
            },
            {
                "type": "bool",
                "name": "stateful",
                "doc": "Boolean (default False). If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch"
            },
            {
                "type": "float",
                "name": "dropout",
                "doc": "Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs"
            },
            {
                "type": "float",
                "name": "recurrent_dropout",
                "doc": "Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state"
            }
        ]
    },
    "Convolution1D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "filters",
                "doc": "Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution)"
            },
            {
                "type": "tuple",
                "name": "kernel_size",
                "doc": "An integer or tuple/list of a single integer, specifying the length of the 1D convolution window"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "An integer or tuple/list of a single integer, specifying the stride length of the convolution Specifying any stride value != 1 is incompatible with specifying any `dilation_rate` value != 1"
            },
            {
                "type": "One of `\"valid\"`, `\"same\"` or `\"causal\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input `\"causal\"` results in causal (dilated) convolutions, e.g. `output[t]` does not depend on `input[t+1:]`. Useful when modeling temporal data where the model should not violate the temporal order See [WaveNet: A Generative Model for Raw Audio, section 2.1](https://arxiv.org/abs/1609.03499)",
                "name": "padding",
                "doc": "One of `\"valid\"`, `\"same\"` or `\"causal\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input `\"causal\"` results in causal (dilated) convolutions, e.g. `output[t]` does not depend on `input[t+1:]`. Useful when modeling temporal data where the model should not violate the temporal order See [WaveNet: A Generative Model for Raw Audio, section 2.1](https://arxiv.org/abs/1609.03499)"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first`"
            },
            {
                "type": "tuple",
                "name": "dilation_rate",
                "doc": "an integer or tuple/list of a single integer, specifying the dilation rate to use for dilated convolution Currently, specifying any `dilation_rate` value != 1 is incompatible with specifying any `strides` value != 1"
            },
            {
                "type": "int",
                "name": "groups",
                "doc": "A positive integer specifying the number of groups in which the input is split along the channel axis. Each group is convolved separately with `filters / groups` filters. The output is the concatenation of all the `groups` results along the channel axis Input channels and `filters` must both be divisible by `groups`"
            },
            {
                "type": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)",
                "name": "activation",
                "doc": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)"
            },
            {
                "type": "Boolean, whether the layer uses a bias vector",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'"
            },
            {
                "type": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'"
            },
            {
                "type": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)",
                "name": "kernel_regularizer",
                "doc": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the bias vector (see `keras.regularizers`)",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)"
            },
            {
                "type": "Constraint function applied to the kernel matrix (see `keras.constraints`)",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the kernel matrix (see `keras.constraints`)"
            },
            {
                "type": "Constraint function applied to the bias vector (see `keras.constraints`)",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector (see `keras.constraints`)"
            }
        ]
    },
    "Convolution1DTranspose": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "filters",
                "doc": "Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution)"
            },
            {
                "type": "int",
                "name": "kernel_size",
                "doc": "An integer length of the 1D convolution window"
            },
            {
                "type": "int",
                "name": "strides",
                "doc": "An integer specifying the stride of the convolution along the time dimension. Specifying a stride value != 1 is incompatible with specifying a `dilation_rate` value != 1. Defaults to 1"
            },
            {
                "type": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "int",
                "name": "output_padding",
                "doc": "An integer specifying the amount of padding along the time dimension of the output tensor The amount of output padding must be lower than the stride If set to `None` (default), the output shape is inferred"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch_size, length, channels)` while `channels_first` corresponds to inputs with shape `(batch_size, channels, length)`"
            },
            {
                "type": "int",
                "name": "dilation_rate",
                "doc": "an integer, specifying the dilation rate to use for dilated convolution Currently, specifying a `dilation_rate` value != 1 is incompatible with specifying a stride value != 1 Also dilation rate larger than 1 is not currently supported"
            },
            {
                "type": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)",
                "name": "activation",
                "doc": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)"
            },
            {
                "type": "Boolean, whether the layer uses a bias vector",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'"
            },
            {
                "type": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'"
            },
            {
                "type": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)",
                "name": "kernel_regularizer",
                "doc": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the bias vector (see `keras.regularizers`)",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)"
            },
            {
                "type": "Constraint function applied to the kernel matrix (see `keras.constraints`)",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the kernel matrix (see `keras.constraints`)"
            },
            {
                "type": "Constraint function applied to the bias vector (see `keras.constraints`)",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector (see `keras.constraints`)"
            }
        ]
    },
    "Convolution2D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "filters",
                "doc": "Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution)"
            },
            {
                "type": "tuple",
                "name": "kernel_size",
                "doc": "An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any `dilation_rate` value != 1"
            },
            {
                "type": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input. When `padding=\"same\"` and `strides=1`, the output has the same size as the input",
                "name": "padding",
                "doc": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input. When `padding=\"same\"` and `strides=1`, the output has the same size as the input"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs. `channels_last` corresponds to inputs with shape `(batch_size, height, width, channels)` while `channels_first` corresponds to inputs with shape `(batch_size, channels, height, width)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be `channels_last`"
            },
            {
                "type": "tuple",
                "name": "dilation_rate",
                "doc": "an integer or tuple/list of 2 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any `dilation_rate` value != 1 is incompatible with specifying any stride value != 1"
            },
            {
                "type": "int",
                "name": "groups",
                "doc": "A positive integer specifying the number of groups in which the input is split along the channel axis. Each group is convolved separately with `filters / groups` filters. The output is the concatenation of all the `groups` results along the channel axis. Input channels and `filters` must both be divisible by `groups`"
            },
            {
                "type": "Activation function to use. If you don't specify anything, no activation is applied (see `keras.activations`)",
                "name": "activation",
                "doc": "Activation function to use. If you don't specify anything, no activation is applied (see `keras.activations`)"
            },
            {
                "type": "Boolean, whether the layer uses a bias vector",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'"
            },
            {
                "type": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'"
            },
            {
                "type": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)",
                "name": "kernel_regularizer",
                "doc": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the bias vector (see `keras.regularizers`)",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)"
            },
            {
                "type": "Constraint function applied to the kernel matrix (see `keras.constraints`)",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the kernel matrix (see `keras.constraints`)"
            },
            {
                "type": "Constraint function applied to the bias vector (see `keras.constraints`)",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector (see `keras.constraints`)"
            }
        ]
    },
    "Convolution2DTranspose": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "filters",
                "doc": "Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution)"
            },
            {
                "type": "tuple",
                "name": "kernel_size",
                "doc": "An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window Can be a single integer to specify the same value for all spatial dimensions"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width Can be a single integer to specify the same value for all spatial dimensions Specifying any stride value != 1 is incompatible with specifying any `dilation_rate` value != 1"
            },
            {
                "type": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "tuple",
                "name": "output_padding",
                "doc": "An integer or tuple/list of 2 integers, specifying the amount of padding along the height and width of the output tensor Can be a single integer to specify the same value for all spatial dimensions The amount of output padding along a given dimension must be lower than the stride along that same dimension If set to `None` (default), the output shape is inferred"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch_size, height, width, channels)` while `channels_first` corresponds to inputs with shape `(batch_size, channels, height, width)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "tuple",
                "name": "dilation_rate",
                "doc": "an integer or tuple/list of 2 integers, specifying the dilation rate to use for dilated convolution Can be a single integer to specify the same value for all spatial dimensions Currently, specifying any `dilation_rate` value != 1 is incompatible with specifying any stride value != 1"
            },
            {
                "type": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)",
                "name": "activation",
                "doc": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)"
            },
            {
                "type": "Boolean, whether the layer uses a bias vector",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'"
            },
            {
                "type": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'"
            },
            {
                "type": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)",
                "name": "kernel_regularizer",
                "doc": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the bias vector (see `keras.regularizers`)",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)"
            },
            {
                "type": "Constraint function applied to the kernel matrix (see `keras.constraints`)",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the kernel matrix (see `keras.constraints`)"
            },
            {
                "type": "Constraint function applied to the bias vector (see `keras.constraints`)",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector (see `keras.constraints`)"
            }
        ]
    },
    "Convolution3D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "filters",
                "doc": "Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution)"
            },
            {
                "type": "tuple",
                "name": "kernel_size",
                "doc": "An integer or tuple/list of 3 integers, specifying the depth, height and width of the 3D convolution window. Can be a single integer to specify the same value for all spatial dimensions"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "An integer or tuple/list of 3 integers, specifying the strides of the convolution along each spatial dimension. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any `dilation_rate` value != 1"
            },
            {
                "type": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs. `channels_last` corresponds to inputs with shape `batch_shape + (spatial_dim1, spatial_dim2, spatial_dim3, channels)` while `channels_first` corresponds to inputs with shape `batch_shape + (channels, spatial_dim1, spatial_dim2, spatial_dim3)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "tuple",
                "name": "dilation_rate",
                "doc": "an integer or tuple/list of 3 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any `dilation_rate` value != 1 is incompatible with specifying any stride value != 1"
            },
            {
                "type": "int",
                "name": "groups",
                "doc": "A positive integer specifying the number of groups in which the input is split along the channel axis. Each group is convolved separately with `filters / groups` filters. The output is the concatenation of all the `groups` results along the channel axis. Input channels and `filters` must both be divisible by `groups`"
            },
            {
                "type": "Activation function to use. If you don't specify anything, no activation is applied (see `keras.activations`)",
                "name": "activation",
                "doc": "Activation function to use. If you don't specify anything, no activation is applied (see `keras.activations`)"
            },
            {
                "type": "Boolean, whether the layer uses a bias vector",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'"
            },
            {
                "type": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'"
            },
            {
                "type": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)",
                "name": "kernel_regularizer",
                "doc": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the bias vector (see `keras.regularizers`)",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)"
            },
            {
                "type": "Constraint function applied to the kernel matrix (see `keras.constraints`)",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the kernel matrix (see `keras.constraints`)"
            },
            {
                "type": "Constraint function applied to the bias vector (see `keras.constraints`)",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector (see `keras.constraints`)"
            }
        ]
    },
    "Convolution3DTranspose": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "filters",
                "doc": "Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution)"
            },
            {
                "type": "tuple",
                "name": "kernel_size",
                "doc": "An integer or tuple/list of 3 integers, specifying the depth, height and width of the 3D convolution window Can be a single integer to specify the same value for all spatial dimensions"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "An integer or tuple/list of 3 integers, specifying the strides of the convolution along the depth, height and width Can be a single integer to specify the same value for all spatial dimensions Specifying any stride value != 1 is incompatible with specifying any `dilation_rate` value != 1"
            },
            {
                "type": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "tuple",
                "name": "output_padding",
                "doc": "An integer or tuple/list of 3 integers, specifying the amount of padding along the depth, height, and width Can be a single integer to specify the same value for all spatial dimensions The amount of output padding along a given dimension must be lower than the stride along that same dimension If set to `None` (default), the output shape is inferred"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch_size, depth, height, width, channels)` while `channels_first` corresponds to inputs with shape `(batch_size, channels, depth, height, width)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "tuple",
                "name": "dilation_rate",
                "doc": "an integer or tuple/list of 3 integers, specifying the dilation rate to use for dilated convolution Can be a single integer to specify the same value for all spatial dimensions Currently, specifying any `dilation_rate` value != 1 is incompatible with specifying any stride value != 1"
            },
            {
                "type": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)",
                "name": "activation",
                "doc": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)"
            },
            {
                "type": "Boolean, whether the layer uses a bias vector",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix (see `keras.initializers`). Defaults to 'glorot_uniform'"
            },
            {
                "type": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector (see `keras.initializers`). Defaults to 'zeros'"
            },
            {
                "type": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)",
                "name": "kernel_regularizer",
                "doc": "Regularizer function applied to the `kernel` weights matrix (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the bias vector (see `keras.regularizers`)",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)"
            },
            {
                "type": "Constraint function applied to the kernel matrix (see `keras.constraints`)",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the kernel matrix (see `keras.constraints`)"
            },
            {
                "type": "Constraint function applied to the bias vector (see `keras.constraints`)",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector (see `keras.constraints`)"
            }
        ]
    },
    "Cropping1D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "tuple",
                "name": "cropping",
                "doc": "Int or tuple of int (length 2) How many units should be trimmed off at the beginning and end of the cropping dimension (axis 1) If a single int is provided, the same value will be used for both"
            }
        ]
    },
    "Cropping2D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "tuple",
                "name": "cropping",
                "doc": "Int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints - If int: the same symmetric cropping is applied to height and width - If tuple of 2 ints: interpreted as two different symmetric cropping values for height and width: `(symmetric_height_crop, symmetric_width_crop)` - If tuple of 2 tuples of 2 ints: interpreted as `((top_crop, bottom_crop), (left_crop, right_crop))` data_format: A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch_size, height, width, channels)` while `channels_first` corresponds to inputs with shape `(batch_size, channels, height, width)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "Any"
            }
        ]
    },
    "Cropping3D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "tuple",
                "name": "cropping",
                "doc": "Int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints - If int: the same symmetric cropping is applied to depth, height, and width - If tuple of 3 ints: interpreted as two different symmetric cropping values for depth, height, and width: `(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop)` - If tuple of 3 tuples of 2 ints: interpreted as `((left_dim1_crop, right_dim1_crop), (left_dim2_crop, right_dim2_crop), (left_dim3_crop, right_dim3_crop))` data_format: A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)` while `channels_first` corresponds to inputs with shape `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "Any"
            }
        ]
    },
    "Dense": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "units",
                "doc": "Positive integer, dimensionality of the output space"
            },
            {
                "type": "Activation function to use If you don't specify anything, no activation is applied (ie. \"linear\" activation: `a(x) = x`)",
                "name": "activation",
                "doc": "Activation function to use If you don't specify anything, no activation is applied (ie. \"linear\" activation: `a(x) = x`)"
            },
            {
                "type": "Boolean, whether the layer uses a bias vector",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix"
            },
            {
                "type": "Initializer for the bias vector",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector"
            },
            {
                "type": "Regularizer function applied to the `kernel` weights matrix",
                "name": "kernel_regularizer",
                "doc": "Regularizer function applied to the `kernel` weights matrix"
            },
            {
                "type": "Regularizer function applied to the bias vector",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector"
            },
            {
                "type": "Regularizer function applied to the output of the layer (its \"activation\")",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to the output of the layer (its \"activation\")"
            },
            {
                "type": "Constraint function applied to the `kernel` weights matrix",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the `kernel` weights matrix"
            },
            {
                "type": "Constraint function applied to the bias vector",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector"
            }
        ]
    },
    "DepthwiseConv1D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "kernel_size",
                "doc": "An integer, specifying the height and width of the 1D convolution window. Can be a single integer to specify the same value for all spatial dimensions"
            },
            {
                "type": "int",
                "name": "strides",
                "doc": "An integer, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any `dilation_rate` value != 1"
            },
            {
                "type": "one of `'valid'` or `'same'` (case-insensitive). `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "one of `'valid'` or `'same'` (case-insensitive). `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "The number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to `filters_in * depth_multiplier`",
                "name": "depth_multiplier",
                "doc": "The number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to `filters_in * depth_multiplier`"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs. `channels_last` corresponds to inputs with shape `(batch_size, height, width, channels)` while `channels_first` corresponds to inputs with shape `(batch_size, channels, height, width)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be 'channels_last'"
            },
            {
                "type": "int",
                "name": "dilation_rate",
                "doc": "A single integer, specifying the dilation rate to use for dilated convolution. Currently, specifying any `dilation_rate` value != 1 is incompatible with specifying any stride value != 1"
            },
            {
                "type": "Activation function to use. If you don't specify anything, no activation is applied (see `keras.activations`)",
                "name": "activation",
                "doc": "Activation function to use. If you don't specify anything, no activation is applied (see `keras.activations`)"
            },
            {
                "type": "Boolean, whether the layer uses a bias vector",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the depthwise kernel matrix (see `keras.initializers`). If None, the default initializer ('glorot_uniform') will be used",
                "name": "depthwise_initializer",
                "doc": "Initializer for the depthwise kernel matrix (see `keras.initializers`). If None, the default initializer ('glorot_uniform') will be used"
            },
            {
                "type": "Initializer for the bias vector (see `keras.initializers`). If None, the default initializer ('zeros') will be used",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector (see `keras.initializers`). If None, the default initializer ('zeros') will be used"
            },
            {
                "type": "Regularizer function applied to the depthwise kernel matrix (see `keras.regularizers`)",
                "name": "depthwise_regularizer",
                "doc": "Regularizer function applied to the depthwise kernel matrix (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the bias vector (see `keras.regularizers`)",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the output of the layer (its 'activation') (see `keras.regularizers`)",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to the output of the layer (its 'activation') (see `keras.regularizers`)"
            },
            {
                "type": "Constraint function applied to the depthwise kernel matrix (see `keras.constraints`)",
                "name": "depthwise_constraint",
                "doc": "Constraint function applied to the depthwise kernel matrix (see `keras.constraints`)"
            },
            {
                "type": "Constraint function applied to the bias vector (see `keras.constraints`)",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector (see `keras.constraints`)"
            }
        ]
    },
    "DepthwiseConv2D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "tuple",
                "name": "kernel_size",
                "doc": "An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any `dilation_rate` value != 1"
            },
            {
                "type": "one of `'valid'` or `'same'` (case-insensitive). `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "one of `'valid'` or `'same'` (case-insensitive). `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "The number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to `filters_in * depth_multiplier`",
                "name": "depth_multiplier",
                "doc": "The number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to `filters_in * depth_multiplier`"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs. `channels_last` corresponds to inputs with shape `(batch_size, height, width, channels)` while `channels_first` corresponds to inputs with shape `(batch_size, channels, height, width)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be 'channels_last'"
            },
            {
                "type": "tuple",
                "name": "dilation_rate",
                "doc": "An integer or tuple/list of 2 integers, specifying the dilation rate to use for dilated convolution. Currently, specifying any `dilation_rate` value != 1 is incompatible with specifying any `strides` value != 1"
            },
            {
                "type": "Activation function to use. If you don't specify anything, no activation is applied (see `keras.activations`)",
                "name": "activation",
                "doc": "Activation function to use. If you don't specify anything, no activation is applied (see `keras.activations`)"
            },
            {
                "type": "Boolean, whether the layer uses a bias vector",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the depthwise kernel matrix (see `keras.initializers`). If None, the default initializer ('glorot_uniform') will be used",
                "name": "depthwise_initializer",
                "doc": "Initializer for the depthwise kernel matrix (see `keras.initializers`). If None, the default initializer ('glorot_uniform') will be used"
            },
            {
                "type": "Initializer for the bias vector (see `keras.initializers`). If None, the default initializer ('zeros') will be used",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector (see `keras.initializers`). If None, the default initializer ('zeros') will be used"
            },
            {
                "type": "Regularizer function applied to the depthwise kernel matrix (see `keras.regularizers`)",
                "name": "depthwise_regularizer",
                "doc": "Regularizer function applied to the depthwise kernel matrix (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the bias vector (see `keras.regularizers`)",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the output of the layer (its 'activation') (see `keras.regularizers`)",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to the output of the layer (its 'activation') (see `keras.regularizers`)"
            },
            {
                "type": "Constraint function applied to the depthwise kernel matrix (see `keras.constraints`)",
                "name": "depthwise_constraint",
                "doc": "Constraint function applied to the depthwise kernel matrix (see `keras.constraints`)"
            },
            {
                "type": "Constraint function applied to the bias vector (see `keras.constraints`)",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector (see `keras.constraints`)"
            }
        ]
    },
    "Discretization": {
        "multipleInputs": false,
        "doc": "A preprocessing layer which buckets continuous features by ranges\n",
        "altersShape": true,
        "params": [
            {
                "type": "Any",
                "name": "bin_boundaries",
                "doc": "Any"
            },
            {
                "type": "Any",
                "name": "num_bins",
                "doc": "Any"
            },
            {
                "type": "Any",
                "name": "epsilon",
                "doc": "Any"
            },
            {
                "type": "Any",
                "name": "output_mode",
                "doc": "Any"
            },
            {
                "type": "Any",
                "name": "sparse",
                "doc": "Any"
            }
        ]
    },
    "Dot": {
        "multipleInputs": false,
        "doc": "Layer that computes a dot product between samples in two tensors\n",
        "altersShape": true,
        "params": [
            {
                "type": "Any",
                "name": "axes",
                "doc": "Any"
            },
            {
                "type": "Any",
                "name": "normalize",
                "doc": "Any"
            }
        ]
    },
    "Dropout": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "float",
                "name": "rate",
                "doc": "Float between 0 and 1. Fraction of the input units to drop"
            },
            {
                "type": "int",
                "name": "noise_shape",
                "doc": "1D integer tensor representing the shape of the binary dropout mask that will be multiplied with the input For instance, if your inputs have shape `(batch_size, timesteps, features)` and you want the dropout mask to be the same for all timesteps, you can use `noise_shape=(batch_size, 1, features)`"
            },
            {
                "type": "int",
                "name": "seed",
                "doc": "A Python integer to use as random seed"
            }
        ]
    },
    "ELU": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "Scale for the negative factor",
                "name": "alpha",
                "doc": "Scale for the negative factor"
            }
        ]
    },
    "Embedding": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "input_dim",
                "doc": "Integer. Size of the vocabulary, i.e. maximum integer index + 1"
            },
            {
                "type": "int",
                "name": "output_dim",
                "doc": "Integer. Dimension of the dense embedding"
            },
            {
                "type": "Initializer for the `embeddings` matrix (see `keras.initializers`)",
                "name": "embeddings_initializer",
                "doc": "Initializer for the `embeddings` matrix (see `keras.initializers`)"
            },
            {
                "type": "Regularizer function applied to the `embeddings` matrix (see `keras.regularizers`)",
                "name": "embeddings_regularizer",
                "doc": "Regularizer function applied to the `embeddings` matrix (see `keras.regularizers`)"
            },
            {
                "type": "Any",
                "name": "activity_regularizer",
                "doc": "Any"
            },
            {
                "type": "Constraint function applied to the `embeddings` matrix (see `keras.constraints`)",
                "name": "embeddings_constraint",
                "doc": "Constraint function applied to the `embeddings` matrix (see `keras.constraints`)"
            },
            {
                "type": "bool",
                "name": "mask_zero",
                "doc": "Boolean, whether or not the input value 0 is a special \"padding\" value that should be masked out This is useful when using recurrent layers which may take variable length input If this is `True`, then all subsequent layers in the model need to support masking or an exception will be raised If mask_zero is set to True, as a consequence, index 0 cannot be used in the vocabulary (input_dim should equal size of vocabulary + 1)"
            },
            {
                "type": "Length of input sequences, when it is constant This argument is required if you are going to connect `Flatten` then `Dense` layers upstream (without it, the shape of the dense outputs cannot be computed)",
                "name": "input_length",
                "doc": "Length of input sequences, when it is constant This argument is required if you are going to connect `Flatten` then `Dense` layers upstream (without it, the shape of the dense outputs cannot be computed)"
            }
        ]
    },
    "Flatten": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, ..., channels)` while `channels_first` corresponds to inputs with shape `(batch, channels, ...)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            }
        ]
    },
    "GRU": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "units",
                "doc": "Positive integer, dimensionality of the output space"
            },
            {
                "type": "Activation function to use Default: hyperbolic tangent (`tanh`) If you pass `None`, no activation is applied (ie. \"linear\" activation: `a(x) = x`)",
                "name": "activation",
                "doc": "Activation function to use Default: hyperbolic tangent (`tanh`) If you pass `None`, no activation is applied (ie. \"linear\" activation: `a(x) = x`)"
            },
            {
                "type": "Activation function to use for the recurrent step Default: sigmoid (`sigmoid`) If you pass `None`, no activation is applied (ie. \"linear\" activation: `a(x) = x`)",
                "name": "recurrent_activation",
                "doc": "Activation function to use for the recurrent step Default: sigmoid (`sigmoid`) If you pass `None`, no activation is applied (ie. \"linear\" activation: `a(x) = x`)"
            },
            {
                "type": "bool",
                "name": "use_bias",
                "doc": "Boolean, (default `True`), whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs. Default: `glorot_uniform`",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs. Default: `glorot_uniform`"
            },
            {
                "type": "Initializer for the `recurrent_kernel` weights matrix, used for the linear transformation of the recurrent state. Default: `orthogonal`",
                "name": "recurrent_initializer",
                "doc": "Initializer for the `recurrent_kernel` weights matrix, used for the linear transformation of the recurrent state. Default: `orthogonal`"
            },
            {
                "type": "Initializer for the bias vector. Default: `zeros`",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector. Default: `zeros`"
            },
            {
                "type": "Regularizer function applied to the `kernel` weights matrix. Default: `None`",
                "name": "kernel_regularizer",
                "doc": "Regularizer function applied to the `kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Regularizer function applied to the `recurrent_kernel` weights matrix. Default: `None`",
                "name": "recurrent_regularizer",
                "doc": "Regularizer function applied to the `recurrent_kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Regularizer function applied to the bias vector. Default: `None`",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector. Default: `None`"
            },
            {
                "type": "Regularizer function applied to the output of the layer (its \"activation\"). Default: `None`",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to the output of the layer (its \"activation\"). Default: `None`"
            },
            {
                "type": "Constraint function applied to the `kernel` weights matrix. Default: `None`",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the `kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Constraint function applied to the `recurrent_kernel` weights matrix. Default: `None`",
                "name": "recurrent_constraint",
                "doc": "Constraint function applied to the `recurrent_kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Constraint function applied to the bias vector. Default: `None`",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector. Default: `None`"
            },
            {
                "type": "float",
                "name": "dropout",
                "doc": "Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs. Default: 0"
            },
            {
                "type": "float",
                "name": "recurrent_dropout",
                "doc": "Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state. Default: 0"
            },
            {
                "type": "bool",
                "name": "return_sequences",
                "doc": "Boolean. Whether to return the last output in the output sequence, or the full sequence. Default: `False`"
            },
            {
                "type": "bool",
                "name": "return_state",
                "doc": "Boolean. Whether to return the last state in addition to the output. Default: `False`"
            },
            {
                "type": "bool",
                "name": "go_backwards",
                "doc": "Boolean (default `False`) If True, process the input sequence backwards and return the reversed sequence"
            },
            {
                "type": "bool",
                "name": "stateful",
                "doc": "Boolean (default False). If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch"
            },
            {
                "type": "bool",
                "name": "unroll",
                "doc": "Boolean (default False) If True, the network will be unrolled, else a symbolic loop will be used Unrolling can speed-up a RNN, although it tends to be more memory-intensive Unrolling is only suitable for short sequences"
            },
            {
                "type": "bool",
                "name": "time_major",
                "doc": "The shape format of the `inputs` and `outputs` tensors If True, the inputs and outputs will be in shape `[timesteps, batch, feature]`, whereas in the False case, it will be `[batch, timesteps, feature]`. Using `time_major = True` is a bit more efficient because it avoids transposes at the beginning and end of the RNN calculation. However, most TensorFlow data is batch-major, so by default this function accepts input and emits output in batch-major form"
            },
            {
                "type": "bool",
                "name": "reset_after",
                "doc": "GRU convention (whether to apply reset gate after or before matrix multiplication). False = \"before\", True = \"after\" (default and cuDNN compatible)"
            }
        ]
    },
    "GRUCell": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "units",
                "doc": "Positive integer, dimensionality of the output space"
            },
            {
                "type": "Activation function to use. Default: hyperbolic tangent (`tanh`). If you pass None, no activation is applied (ie. \"linear\" activation: `a(x) = x`)",
                "name": "activation",
                "doc": "Activation function to use. Default: hyperbolic tangent (`tanh`). If you pass None, no activation is applied (ie. \"linear\" activation: `a(x) = x`)"
            },
            {
                "type": "Activation function to use for the recurrent step Default: sigmoid (`sigmoid`). If you pass `None`, no activation is applied (ie. \"linear\" activation: `a(x) = x`)",
                "name": "recurrent_activation",
                "doc": "Activation function to use for the recurrent step Default: sigmoid (`sigmoid`). If you pass `None`, no activation is applied (ie. \"linear\" activation: `a(x) = x`)"
            },
            {
                "type": "bool",
                "name": "use_bias",
                "doc": "Boolean, (default `True`), whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs. Default: `glorot_uniform`",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs. Default: `glorot_uniform`"
            },
            {
                "type": "Initializer for the `recurrent_kernel` weights matrix, used for the linear transformation of the recurrent state Default: `orthogonal`",
                "name": "recurrent_initializer",
                "doc": "Initializer for the `recurrent_kernel` weights matrix, used for the linear transformation of the recurrent state Default: `orthogonal`"
            },
            {
                "type": "Initializer for the bias vector. Default: `zeros`",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector. Default: `zeros`"
            },
            {
                "type": "Regularizer function applied to the `kernel` weights matrix. Default: `None`",
                "name": "kernel_regularizer",
                "doc": "Regularizer function applied to the `kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Regularizer function applied to the `recurrent_kernel` weights matrix. Default: `None`",
                "name": "recurrent_regularizer",
                "doc": "Regularizer function applied to the `recurrent_kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Regularizer function applied to the bias vector. Default: `None`",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector. Default: `None`"
            },
            {
                "type": "Constraint function applied to the `kernel` weights matrix. Default: `None`",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the `kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Constraint function applied to the `recurrent_kernel` weights matrix. Default: `None`",
                "name": "recurrent_constraint",
                "doc": "Constraint function applied to the `recurrent_kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Constraint function applied to the bias vector. Default: `None`",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector. Default: `None`"
            },
            {
                "type": "float",
                "name": "dropout",
                "doc": "Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs. Default: 0"
            },
            {
                "type": "float",
                "name": "recurrent_dropout",
                "doc": "Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state. Default: 0"
            },
            {
                "type": "bool",
                "name": "reset_after",
                "doc": "GRU convention (whether to apply reset gate after or before matrix multiplication). False = \"before\", True = \"after\" (default and cuDNN compatible)"
            }
        ]
    },
    "GaussianDropout": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "float",
                "name": "rate",
                "doc": "Float, drop probability (as with `Dropout`) The multiplicative noise will have standard deviation `sqrt(rate / (1 - rate))`"
            },
            {
                "type": "int",
                "name": "seed",
                "doc": "Integer, optional random seed to enable deterministic behavior"
            }
        ]
    },
    "GaussianNoise": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "float",
                "name": "stddev",
                "doc": "Float, standard deviation of the noise distribution"
            },
            {
                "type": "int",
                "name": "seed",
                "doc": "Integer, optional random seed to enable deterministic behavior"
            }
        ]
    },
    "GlobalAveragePooling1D": {
        "multipleInputs": false,
        "doc": "keepdims: A boolean, whether to keep the temporal dimension or not If `keepdims` is `False` (default), the rank of the tensor is reduced for spatial dimensions If `keepdims` is `True`, the temporal dimension are retained with length 1 The behavior is the same as for `tf.reduce_mean` or `np.mean`\n",
        "altersShape": true,
        "params": [
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, steps, features)` while `channels_first` corresponds to inputs with shape `(batch, features, steps)`"
            }
        ]
    },
    "GlobalAveragePooling2D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first`. The ordering of the dimensions in the inputs. `channels_last` corresponds to inputs with shape `(batch, height, width, channels)` while `channels_first` corresponds to inputs with shape `(batch, channels, height, width)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "bool",
                "name": "keepdims",
                "doc": "A boolean, whether to keep the spatial dimensions or not. If `keepdims` is `False` (default), the rank of the tensor is reduced for spatial dimensions. If `keepdims` is `True`, the spatial dimensions are retained with length 1. The behavior is the same as for `tf.reduce_mean` or `np.mean`"
            }
        ]
    },
    "GlobalAveragePooling3D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)` while `channels_first` corresponds to inputs with shape `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "bool",
                "name": "keepdims",
                "doc": "A boolean, whether to keep the spatial dimensions or not If `keepdims` is `False` (default), the rank of the tensor is reduced for spatial dimensions If `keepdims` is `True`, the spatial dimensions are retained with length 1 The behavior is the same as for `tf.reduce_mean` or `np.mean`"
            }
        ]
    },
    "GlobalAvgPool1D": {
        "multipleInputs": false,
        "doc": "keepdims: A boolean, whether to keep the temporal dimension or not If `keepdims` is `False` (default), the rank of the tensor is reduced for spatial dimensions If `keepdims` is `True`, the temporal dimension are retained with length 1 The behavior is the same as for `tf.reduce_mean` or `np.mean`\n",
        "altersShape": true,
        "params": [
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, steps, features)` while `channels_first` corresponds to inputs with shape `(batch, features, steps)`"
            }
        ]
    },
    "GlobalAvgPool2D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first`. The ordering of the dimensions in the inputs. `channels_last` corresponds to inputs with shape `(batch, height, width, channels)` while `channels_first` corresponds to inputs with shape `(batch, channels, height, width)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "bool",
                "name": "keepdims",
                "doc": "A boolean, whether to keep the spatial dimensions or not. If `keepdims` is `False` (default), the rank of the tensor is reduced for spatial dimensions. If `keepdims` is `True`, the spatial dimensions are retained with length 1. The behavior is the same as for `tf.reduce_mean` or `np.mean`"
            }
        ]
    },
    "GlobalAvgPool3D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)` while `channels_first` corresponds to inputs with shape `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "bool",
                "name": "keepdims",
                "doc": "A boolean, whether to keep the spatial dimensions or not If `keepdims` is `False` (default), the rank of the tensor is reduced for spatial dimensions If `keepdims` is `True`, the spatial dimensions are retained with length 1 The behavior is the same as for `tf.reduce_mean` or `np.mean`"
            }
        ]
    },
    "GlobalMaxPool1D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, steps, features)` while `channels_first` corresponds to inputs with shape `(batch, features, steps)`"
            },
            {
                "type": "bool",
                "name": "keepdims",
                "doc": "A boolean, whether to keep the temporal dimension or not If `keepdims` is `False` (default), the rank of the tensor is reduced for spatial dimensions If `keepdims` is `True`, the temporal dimension are retained with length 1 The behavior is the same as for `tf.reduce_max` or `np.max`"
            }
        ]
    },
    "GlobalMaxPool2D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, height, width, channels)` while `channels_first` corresponds to inputs with shape `(batch, channels, height, width)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "bool",
                "name": "keepdims",
                "doc": "A boolean, whether to keep the spatial dimensions or not If `keepdims` is `False` (default), the rank of the tensor is reduced for spatial dimensions If `keepdims` is `True`, the spatial dimensions are retained with length 1 The behavior is the same as for `tf.reduce_max` or `np.max`"
            }
        ]
    },
    "GlobalMaxPool3D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)` while `channels_first` corresponds to inputs with shape `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "bool",
                "name": "keepdims",
                "doc": "A boolean, whether to keep the spatial dimensions or not If `keepdims` is `False` (default), the rank of the tensor is reduced for spatial dimensions If `keepdims` is `True`, the spatial dimensions are retained with length 1 The behavior is the same as for `tf.reduce_max` or `np.max`"
            }
        ]
    },
    "GlobalMaxPooling1D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, steps, features)` while `channels_first` corresponds to inputs with shape `(batch, features, steps)`"
            },
            {
                "type": "bool",
                "name": "keepdims",
                "doc": "A boolean, whether to keep the temporal dimension or not If `keepdims` is `False` (default), the rank of the tensor is reduced for spatial dimensions If `keepdims` is `True`, the temporal dimension are retained with length 1 The behavior is the same as for `tf.reduce_max` or `np.max`"
            }
        ]
    },
    "GlobalMaxPooling2D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, height, width, channels)` while `channels_first` corresponds to inputs with shape `(batch, channels, height, width)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "bool",
                "name": "keepdims",
                "doc": "A boolean, whether to keep the spatial dimensions or not If `keepdims` is `False` (default), the rank of the tensor is reduced for spatial dimensions If `keepdims` is `True`, the spatial dimensions are retained with length 1 The behavior is the same as for `tf.reduce_max` or `np.max`"
            }
        ]
    },
    "GlobalMaxPooling3D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)` while `channels_first` corresponds to inputs with shape `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "bool",
                "name": "keepdims",
                "doc": "A boolean, whether to keep the spatial dimensions or not If `keepdims` is `False` (default), the rank of the tensor is reduced for spatial dimensions If `keepdims` is `True`, the spatial dimensions are retained with length 1 The behavior is the same as for `tf.reduce_max` or `np.max`"
            }
        ]
    },
    "Hashing": {
        "multipleInputs": false,
        "doc": "**kwargs: Keyword arguments to construct a layer\n",
        "altersShape": true,
        "params": [
            {
                "type": "Number of hash bins. Note that this includes the `mask_value` bin, so the effective number of bins is `(num_bins - 1)` if `mask_value` is set",
                "name": "num_bins",
                "doc": "Number of hash bins. Note that this includes the `mask_value` bin, so the effective number of bins is `(num_bins - 1)` if `mask_value` is set"
            },
            {
                "type": "A value that represents masked inputs, which are mapped to index 0. Defaults to None, meaning no mask term will be added and the hashing will start at index 0",
                "name": "mask_value",
                "doc": "A value that represents masked inputs, which are mapped to index 0. Defaults to None, meaning no mask term will be added and the hashing will start at index 0"
            },
            {
                "type": "int",
                "name": "salt",
                "doc": "A single unsigned integer or None If passed, the hash function used will be SipHash64, with these values used as an additional input (known as a \"salt\" in cryptography) These should be non-zero. Defaults to `None` (in that case, the FarmHash64 hash function is used). It also supports tuple/list of 2 unsigned integer numbers, see reference paper for details"
            },
            {
                "type": "Specification for the output of the layer. Defaults to `\"int\"` Values can be `\"int\"`, `\"one_hot\"`, `\"multi_hot\"`, or `\"count\"` configuring the layer as follows: - `\"int\"`: Return the integer bin indices directly. - `\"one_hot\"`: Encodes each individual element in the input into an array the same size as `num_bins`, containing a 1 at the input's bin index. If the last dimension is size 1, will encode on that dimension. If the last dimension is not size 1, will append a new dimension for the encoded output. - `\"multi_hot\"`: Encodes each sample in the input into a single array the same size as `num_bins`, containing a 1 for each bin index index present in the sample. Treats the last dimension as the sample dimension, if input shape is `(..., sample_length)`, output shape will be `(..., num_tokens)`. - `\"count\"`: As `\"multi_hot\"`, but the int array contains a count of the number of times the bin index appeared in the sample",
                "name": "output_mode",
                "doc": "Specification for the output of the layer. Defaults to `\"int\"` Values can be `\"int\"`, `\"one_hot\"`, `\"multi_hot\"`, or `\"count\"` configuring the layer as follows: - `\"int\"`: Return the integer bin indices directly. - `\"one_hot\"`: Encodes each individual element in the input into an array the same size as `num_bins`, containing a 1 at the input's bin index. If the last dimension is size 1, will encode on that dimension. If the last dimension is not size 1, will append a new dimension for the encoded output. - `\"multi_hot\"`: Encodes each sample in the input into a single array the same size as `num_bins`, containing a 1 for each bin index index present in the sample. Treats the last dimension as the sample dimension, if input shape is `(..., sample_length)`, output shape will be `(..., num_tokens)`. - `\"count\"`: As `\"multi_hot\"`, but the int array contains a count of the number of times the bin index appeared in the sample"
            },
            {
                "type": "bool",
                "name": "sparse",
                "doc": "Boolean. Only applicable to `\"one_hot\"`, `\"multi_hot\"`, and `\"count\"` output modes. If True, returns a `SparseTensor` instead of a dense `Tensor`. Defaults to False"
            }
        ]
    },
    "IntegerLookup": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "bool",
                "name": "max_tokens",
                "doc": "Maximum size of the vocabulary for this layer. This should only be specified when adapting the vocabulary or when setting `pad_to_max_tokens=True`. If None, there is no cap on the size of the vocabulary. Note that this size includes the OOV and mask tokens. Defaults to None"
            },
            {
                "type": "The number of out-of-vocabulary tokens to use. If this value is more than 1, OOV inputs are modulated to determine their OOV value. If this value is 0, OOV inputs will cause an error when calling the layer. Defaults to 1",
                "name": "num_oov_indices",
                "doc": "The number of out-of-vocabulary tokens to use. If this value is more than 1, OOV inputs are modulated to determine their OOV value. If this value is 0, OOV inputs will cause an error when calling the layer. Defaults to 1"
            },
            {
                "type": "int",
                "name": "mask_token",
                "doc": "An integer token that represents masked inputs. When `output_mode` is `\"int\"`, the token is included in vocabulary and mapped to index 0. In other output modes, the token will not appear in the vocabulary and instances of the mask token in the input will be dropped If set to None, no mask term will be added. Defaults to None"
            },
            {
                "type": "bool",
                "name": "oov_token",
                "doc": "Only used when `invert` is True. The token to return for OOV indices. Defaults to -1"
            },
            {
                "type": "tuple",
                "name": "vocabulary",
                "doc": "Optional. Either an array of integers or a string path to a text file. If passing an array, can pass a tuple, list, 1D numpy array, or 1D tensor containing the integer vocbulary terms. If passing a file path, the file should contain one line per term in the vocabulary. If this argument is set, there is no need to `adapt()` the layer"
            },
            {
                "type": "The dtype of the vocabulary terms, for example `\"int64\"` or `\"int32\"`. Defaults to `\"int64\"`",
                "name": "vocabulary_dtype",
                "doc": "The dtype of the vocabulary terms, for example `\"int64\"` or `\"int32\"`. Defaults to `\"int64\"`"
            },
            {
                "type": "Only valid when `output_mode` is `\"tf_idf\"`. A tuple, list, 1D numpy array, or 1D tensor or the same length as the vocabulary, containing the floating point inverse document frequency weights, which will be multiplied by per sample term counts for the final `tf_idf` weight. If the `vocabulary` argument is set, and `output_mode` is `\"tf_idf\"`, this argument must be supplied",
                "name": "idf_weights",
                "doc": "Only valid when `output_mode` is `\"tf_idf\"`. A tuple, list, 1D numpy array, or 1D tensor or the same length as the vocabulary, containing the floating point inverse document frequency weights, which will be multiplied by per sample term counts for the final `tf_idf` weight. If the `vocabulary` argument is set, and `output_mode` is `\"tf_idf\"`, this argument must be supplied"
            },
            {
                "type": "bool",
                "name": "invert",
                "doc": "Only valid when `output_mode` is `\"int\"`. If True, this layer will map indices to vocabulary items instead of mapping vocabulary items to indices. Default to False"
            },
            {
                "type": "Specification for the output of the layer. Defaults to `\"int\"` Values can be `\"int\"`, `\"one_hot\"`, `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"` configuring the layer as follows: - `\"int\"`: Return the vocabulary indices of the input tokens. - `\"one_hot\"`: Encodes each individual element in the input into an array the same size as the vocabulary, containing a 1 at the element index. If the last dimension is size 1, will encode on that dimension. If the last dimension is not size 1, will append a new dimension for the encoded output. - `\"multi_hot\"`: Encodes each sample in the input into a single array the same size as the vocabulary, containing a 1 for each vocabulary term present in the sample. Treats the last dimension as the sample dimension, if input shape is (..., sample_length), output shape will be (..., num_tokens). - `\"count\"`: As `\"multi_hot\"`, but the int array contains a count of the number of times the token at that index appeared in the sample. - `\"tf_idf\"`: As `\"multi_hot\"`, but the TF-IDF algorithm is applied to find the value in each token slot For `\"int\"` output, any shape of input and output is supported. For all other output modes, currently only output up to rank 2 is supported",
                "name": "output_mode",
                "doc": "Specification for the output of the layer. Defaults to `\"int\"` Values can be `\"int\"`, `\"one_hot\"`, `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"` configuring the layer as follows: - `\"int\"`: Return the vocabulary indices of the input tokens. - `\"one_hot\"`: Encodes each individual element in the input into an array the same size as the vocabulary, containing a 1 at the element index. If the last dimension is size 1, will encode on that dimension. If the last dimension is not size 1, will append a new dimension for the encoded output. - `\"multi_hot\"`: Encodes each sample in the input into a single array the same size as the vocabulary, containing a 1 for each vocabulary term present in the sample. Treats the last dimension as the sample dimension, if input shape is (..., sample_length), output shape will be (..., num_tokens). - `\"count\"`: As `\"multi_hot\"`, but the int array contains a count of the number of times the token at that index appeared in the sample. - `\"tf_idf\"`: As `\"multi_hot\"`, but the TF-IDF algorithm is applied to find the value in each token slot For `\"int\"` output, any shape of input and output is supported. For all other output modes, currently only output up to rank 2 is supported"
            },
            {
                "type": "bool",
                "name": "sparse",
                "doc": "Boolean. Only applicable when `output_mode` is `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"`. If True, returns a `SparseTensor` instead of a dense `Tensor`. Defaults to False"
            },
            {
                "type": "bool",
                "name": "pad_to_max_tokens",
                "doc": "Only applicable when `output_mode` is `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"`. If True, the output will have its feature axis padded to `max_tokens` even if the number of unique tokens in the vocabulary is less than max_tokens, resulting in a tensor of shape [batch_size, max_tokens] regardless of vocabulary size. Defaults to False"
            }
        ]
    },
    "LSTM": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "units",
                "doc": "Positive integer, dimensionality of the output space"
            },
            {
                "type": "Activation function to use Default: hyperbolic tangent (`tanh`). If you pass `None`, no activation is applied (ie. \"linear\" activation: `a(x) = x`)",
                "name": "activation",
                "doc": "Activation function to use Default: hyperbolic tangent (`tanh`). If you pass `None`, no activation is applied (ie. \"linear\" activation: `a(x) = x`)"
            },
            {
                "type": "Activation function to use for the recurrent step Default: sigmoid (`sigmoid`). If you pass `None`, no activation is applied (ie. \"linear\" activation: `a(x) = x`)",
                "name": "recurrent_activation",
                "doc": "Activation function to use for the recurrent step Default: sigmoid (`sigmoid`). If you pass `None`, no activation is applied (ie. \"linear\" activation: `a(x) = x`)"
            },
            {
                "type": "bool",
                "name": "use_bias",
                "doc": "Boolean (default `True`), whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs. Default: `glorot_uniform`",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs. Default: `glorot_uniform`"
            },
            {
                "type": "Initializer for the `recurrent_kernel` weights matrix, used for the linear transformation of the recurrent state Default: `orthogonal`",
                "name": "recurrent_initializer",
                "doc": "Initializer for the `recurrent_kernel` weights matrix, used for the linear transformation of the recurrent state Default: `orthogonal`"
            },
            {
                "type": "Initializer for the bias vector. Default: `zeros`",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector. Default: `zeros`"
            },
            {
                "type": "bool",
                "name": "unit_forget_bias",
                "doc": "Boolean (default `True`). If True, add 1 to the bias of the forget gate at initialization. Setting it to true will also force `bias_initializer=\"zeros\"`. This is recommended in [Jozefowicz et al.](http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)"
            },
            {
                "type": "Regularizer function applied to the `kernel` weights matrix. Default: `None`",
                "name": "kernel_regularizer",
                "doc": "Regularizer function applied to the `kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Regularizer function applied to the `recurrent_kernel` weights matrix. Default: `None`",
                "name": "recurrent_regularizer",
                "doc": "Regularizer function applied to the `recurrent_kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Regularizer function applied to the bias vector. Default: `None`",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector. Default: `None`"
            },
            {
                "type": "Regularizer function applied to the output of the layer (its \"activation\"). Default: `None`",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to the output of the layer (its \"activation\"). Default: `None`"
            },
            {
                "type": "Constraint function applied to the `kernel` weights matrix. Default: `None`",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the `kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Constraint function applied to the `recurrent_kernel` weights matrix. Default: `None`",
                "name": "recurrent_constraint",
                "doc": "Constraint function applied to the `recurrent_kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Constraint function applied to the bias vector. Default: `None`",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector. Default: `None`"
            },
            {
                "type": "float",
                "name": "dropout",
                "doc": "Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs. Default: 0"
            },
            {
                "type": "float",
                "name": "recurrent_dropout",
                "doc": "Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state. Default: 0"
            },
            {
                "type": "bool",
                "name": "return_sequences",
                "doc": "Boolean. Whether to return the last output. in the output sequence, or the full sequence. Default: `False`"
            },
            {
                "type": "bool",
                "name": "return_state",
                "doc": "Boolean. Whether to return the last state in addition to the output. Default: `False`"
            },
            {
                "type": "bool",
                "name": "go_backwards",
                "doc": "Boolean (default `False`). If True, process the input sequence backwards and return the reversed sequence"
            },
            {
                "type": "bool",
                "name": "stateful",
                "doc": "Boolean (default `False`). If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch"
            },
            {
                "type": "bool",
                "name": "time_major",
                "doc": "The shape format of the `inputs` and `outputs` tensors If True, the inputs and outputs will be in shape `[timesteps, batch, feature]`, whereas in the False case, it will be `[batch, timesteps, feature]`. Using `time_major = True` is a bit more efficient because it avoids transposes at the beginning and end of the RNN calculation. However, most TensorFlow data is batch-major, so by default this function accepts input and emits output in batch-major form"
            },
            {
                "type": "bool",
                "name": "unroll",
                "doc": "Boolean (default `False`). If True, the network will be unrolled, else a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences"
            }
        ]
    },
    "LSTMCell": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "units",
                "doc": "Positive integer, dimensionality of the output space"
            },
            {
                "type": "Activation function to use. Default: hyperbolic tangent (`tanh`). If you pass `None`, no activation is applied (ie. \"linear\" activation: `a(x) = x`)",
                "name": "activation",
                "doc": "Activation function to use. Default: hyperbolic tangent (`tanh`). If you pass `None`, no activation is applied (ie. \"linear\" activation: `a(x) = x`)"
            },
            {
                "type": "Activation function to use for the recurrent step Default: sigmoid (`sigmoid`). If you pass `None`, no activation is applied (ie. \"linear\" activation: `a(x) = x`)",
                "name": "recurrent_activation",
                "doc": "Activation function to use for the recurrent step Default: sigmoid (`sigmoid`). If you pass `None`, no activation is applied (ie. \"linear\" activation: `a(x) = x`)"
            },
            {
                "type": "bool",
                "name": "use_bias",
                "doc": "Boolean, (default `True`), whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs. Default: `glorot_uniform`",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs. Default: `glorot_uniform`"
            },
            {
                "type": "Initializer for the `recurrent_kernel` weights matrix, used for the linear transformation of the recurrent state Default: `orthogonal`",
                "name": "recurrent_initializer",
                "doc": "Initializer for the `recurrent_kernel` weights matrix, used for the linear transformation of the recurrent state Default: `orthogonal`"
            },
            {
                "type": "Initializer for the bias vector. Default: `zeros`",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector. Default: `zeros`"
            },
            {
                "type": "bool",
                "name": "unit_forget_bias",
                "doc": "Boolean (default `True`). If True, add 1 to the bias of the forget gate at initialization. Setting it to true will also force `bias_initializer=\"zeros\"`. This is recommended in [Jozefowicz et al.](http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf) kernel_regularizer: Regularizer function applied to the `kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Any",
                "name": "kernel_regularizer",
                "doc": "Any"
            },
            {
                "type": "Regularizer function applied to the `recurrent_kernel` weights matrix. Default: `None`",
                "name": "recurrent_regularizer",
                "doc": "Regularizer function applied to the `recurrent_kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Regularizer function applied to the bias vector. Default: `None`",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector. Default: `None`"
            },
            {
                "type": "Constraint function applied to the `kernel` weights matrix. Default: `None`",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the `kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Constraint function applied to the `recurrent_kernel` weights matrix. Default: `None`",
                "name": "recurrent_constraint",
                "doc": "Constraint function applied to the `recurrent_kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Constraint function applied to the bias vector. Default: `None`",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector. Default: `None`"
            },
            {
                "type": "float",
                "name": "dropout",
                "doc": "Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs. Default: 0"
            },
            {
                "type": "float",
                "name": "recurrent_dropout",
                "doc": "Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state. Default: 0"
            }
        ]
    },
    "Lambda": {
        "multipleInputs": false,
        "doc": "function: The function to be evaluated. Takes input tensor as first argument\noutput_shape: Expected output shape from function. This argument can be inferred if not explicitly provided. Can be a tuple or function. If a tuple, it only specifies the first dimension onward; sample dimension is assumed either the same as the input: `output_shape = (input_shape[0], ) + output_shape` or, the input is `None` and the sample dimension is also `None`: `output_shape = (None, ) + output_shape` If a function, it specifies the entire shape as a function of the input shape: `output_shape = f(input_shape)` mask: Either None (indicating no masking) or a callable with the same signature as the `compute_mask` layer method, or a tensor that will be returned as output mask regardless of what the input is\narguments: Optional dictionary of keyword arguments to be passed to the function\nInput shape: Arbitrary. Use the keyword argument input_shape (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model\nOutput shape: Specified by `output_shape` argument\n",
        "altersShape": true,
        "params": []
    },
    "LayerNormalization": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "axis",
                "doc": "Integer or List/Tuple. The axis or axes to normalize across. Typically this is the features axis/axes. The left-out axes are typically the batch axis/axes. This argument defaults to `-1`, the last dimension in the input"
            },
            {
                "type": "bool",
                "name": "epsilon",
                "doc": "Small float added to variance to avoid dividing by zero. Defaults to 1e-3 center: If True, add offset of `beta` to normalized tensor. If False, `beta` is ignored. Defaults to True"
            },
            {
                "type": "Any",
                "name": "center",
                "doc": "Any"
            },
            {
                "type": "bool",
                "name": "scale",
                "doc": "If True, multiply by `gamma`. If False, `gamma` is not used. Defaults to True. When the next layer is linear (also e.g. `nn.relu`), this can be disabled since the scaling will be done by the next layer"
            },
            {
                "type": "Initializer for the beta weight. Defaults to zeros",
                "name": "beta_initializer",
                "doc": "Initializer for the beta weight. Defaults to zeros"
            },
            {
                "type": "Initializer for the gamma weight. Defaults to ones",
                "name": "gamma_initializer",
                "doc": "Initializer for the gamma weight. Defaults to ones"
            },
            {
                "type": "Optional regularizer for the beta weight. None by default",
                "name": "beta_regularizer",
                "doc": "Optional regularizer for the beta weight. None by default"
            },
            {
                "type": "Optional regularizer for the gamma weight. None by default",
                "name": "gamma_regularizer",
                "doc": "Optional regularizer for the gamma weight. None by default"
            },
            {
                "type": "Optional constraint for the beta weight. None by default",
                "name": "beta_constraint",
                "doc": "Optional constraint for the beta weight. None by default"
            },
            {
                "type": "Optional constraint for the gamma weight. None by default",
                "name": "gamma_constraint",
                "doc": "Optional constraint for the gamma weight. None by default"
            }
        ]
    },
    "LeakyReLU": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "float",
                "name": "alpha",
                "doc": "Float >= 0. Negative slope coefficient. Default to 0.3"
            }
        ]
    },
    "LocallyConnected1D": {
        "multipleInputs": false,
        "doc": "Input shape: 3D tensor with shape: `(batch_size, steps, input_dim)` Output shape: 3D tensor with shape: `(batch_size, new_steps, filters)` `steps` value might have changed due to padding or strides\n",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "filters",
                "doc": "Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution)"
            },
            {
                "type": "tuple",
                "name": "kernel_size",
                "doc": "An integer or tuple/list of a single integer, specifying the length of the 1D convolution window"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "An integer or tuple/list of a single integer, specifying the stride length of the convolution"
            },
            {
                "type": "Currently only supports `\"valid\"` (case-insensitive). `\"same\"` may be supported in the future. `\"valid\"` means no padding",
                "name": "padding",
                "doc": "Currently only supports `\"valid\"` (case-insensitive). `\"same\"` may be supported in the future. `\"valid\"` means no padding"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first`. The ordering of the dimensions in the inputs. `channels_last` corresponds to inputs with shape `(batch, length, channels)` while `channels_first` corresponds to inputs with shape `(batch, channels, length)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "Activation function to use. If you don't specify anything, no activation is applied (ie. \"linear\" activation: `a(x) = x`)",
                "name": "activation",
                "doc": "Activation function to use. If you don't specify anything, no activation is applied (ie. \"linear\" activation: `a(x) = x`)"
            },
            {
                "type": "Boolean, whether the layer uses a bias vector",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix"
            },
            {
                "type": "Initializer for the bias vector",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector"
            },
            {
                "type": "Regularizer function applied to the `kernel` weights matrix",
                "name": "kernel_regularizer",
                "doc": "Regularizer function applied to the `kernel` weights matrix"
            },
            {
                "type": "Regularizer function applied to the bias vector",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector"
            },
            {
                "type": "Regularizer function applied to the output of the layer (its \"activation\").",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to the output of the layer (its \"activation\")."
            },
            {
                "type": "Constraint function applied to the kernel matrix",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the kernel matrix"
            },
            {
                "type": "Constraint function applied to the bias vector",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector"
            },
            {
                "type": "implementation mode, either `1`, `2`, or `3`. `1` loops over input spatial locations to perform the forward pass. It is memory-efficient but performs a lot of (small) ops. `2` stores layer weights in a dense but sparsely-populated 2D matrix and implements the forward pass as a single matrix-multiply. It uses a lot of RAM but performs few (large) ops. `3` stores layer weights in a sparse tensor and implements the forward pass as a single sparse matrix-multiply. How to choose: `1`: large, dense models, `2`: small models, `3`: large, sparse models, where \"large\" stands for large input/output activations (i.e. many `filters`, `input_filters`, large `input_size`, `output_size`), and \"sparse\" stands for few connections between inputs and outputs, i.e. small ratio `filters * input_filters * kernel_size / (input_size * strides)`, where inputs to and outputs of the layer are assumed to have shapes `(input_size, input_filters)`, `(output_size, filters)` respectively. It is recommended to benchmark each in the setting of interest to pick the most efficient one (in terms of speed and memory usage). Correct choice of implementation can lead to dramatic speed improvements (e.g. 50X), potentially at the expense of RAM. Also, only `padding=\"valid\"` is supported by `implementation=1`",
                "name": "implementation",
                "doc": "implementation mode, either `1`, `2`, or `3`. `1` loops over input spatial locations to perform the forward pass. It is memory-efficient but performs a lot of (small) ops. `2` stores layer weights in a dense but sparsely-populated 2D matrix and implements the forward pass as a single matrix-multiply. It uses a lot of RAM but performs few (large) ops. `3` stores layer weights in a sparse tensor and implements the forward pass as a single sparse matrix-multiply. How to choose: `1`: large, dense models, `2`: small models, `3`: large, sparse models, where \"large\" stands for large input/output activations (i.e. many `filters`, `input_filters`, large `input_size`, `output_size`), and \"sparse\" stands for few connections between inputs and outputs, i.e. small ratio `filters * input_filters * kernel_size / (input_size * strides)`, where inputs to and outputs of the layer are assumed to have shapes `(input_size, input_filters)`, `(output_size, filters)` respectively. It is recommended to benchmark each in the setting of interest to pick the most efficient one (in terms of speed and memory usage). Correct choice of implementation can lead to dramatic speed improvements (e.g. 50X), potentially at the expense of RAM. Also, only `padding=\"valid\"` is supported by `implementation=1`"
            }
        ]
    },
    "LocallyConnected2D": {
        "multipleInputs": false,
        "doc": "Input shape: 4D tensor with shape: `(samples, channels, rows, cols)` if data_format='channels_first' or 4D tensor with shape: `(samples, rows, cols, channels)` if data_format='channels_last'\nOutput shape: 4D tensor with shape: `(samples, filters, new_rows, new_cols)` if data_format='channels_first' or 4D tensor with shape: `(samples, new_rows, new_cols, filters)` if data_format='channels_last'. `rows` and `cols` values might have changed due to padding\n",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "filters",
                "doc": "Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution)"
            },
            {
                "type": "tuple",
                "name": "kernel_size",
                "doc": "An integer or tuple/list of 2 integers, specifying the width and height of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "An integer or tuple/list of 2 integers, specifying the strides of the convolution along the width and height. Can be a single integer to specify the same value for all spatial dimensions"
            },
            {
                "type": "Currently only support `\"valid\"` (case-insensitive). `\"same\"` will be supported in future. `\"valid\"` means no padding",
                "name": "padding",
                "doc": "Currently only support `\"valid\"` (case-insensitive). `\"same\"` will be supported in future. `\"valid\"` means no padding"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first`. The ordering of the dimensions in the inputs. `channels_last` corresponds to inputs with shape `(batch, height, width, channels)` while `channels_first` corresponds to inputs with shape `(batch, channels, height, width)`. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "Activation function to use. If you don't specify anything, no activation is applied (ie. \"linear\" activation: `a(x) = x`)",
                "name": "activation",
                "doc": "Activation function to use. If you don't specify anything, no activation is applied (ie. \"linear\" activation: `a(x) = x`)"
            },
            {
                "type": "Boolean, whether the layer uses a bias vector",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix"
            },
            {
                "type": "Initializer for the bias vector",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector"
            },
            {
                "type": "Regularizer function applied to the `kernel` weights matrix",
                "name": "kernel_regularizer",
                "doc": "Regularizer function applied to the `kernel` weights matrix"
            },
            {
                "type": "Regularizer function applied to the bias vector",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector"
            },
            {
                "type": "Regularizer function applied to the output of the layer (its \"activation\")",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to the output of the layer (its \"activation\")"
            },
            {
                "type": "Constraint function applied to the kernel matrix",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the kernel matrix"
            },
            {
                "type": "Constraint function applied to the bias vector",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector"
            },
            {
                "type": "implementation mode, either `1`, `2`, or `3`. `1` loops over input spatial locations to perform the forward pass. It is memory-efficient but performs a lot of (small) ops. `2` stores layer weights in a dense but sparsely-populated 2D matrix and implements the forward pass as a single matrix-multiply. It uses a lot of RAM but performs few (large) ops. `3` stores layer weights in a sparse tensor and implements the forward pass as a single sparse matrix-multiply. How to choose: `1`: large, dense models, `2`: small models, `3`: large, sparse models, where \"large\" stands for large input/output activations (i.e. many `filters`, `input_filters`, large `np.prod(input_size)`, `np.prod(output_size)`), and \"sparse\" stands for few connections between inputs and outputs, i.e. small ratio `filters * input_filters * np.prod(kernel_size) / (np.prod(input_size) * np.prod(strides))`, where inputs to and outputs of the layer are assumed to have shapes `input_size + (input_filters,)`, `output_size + (filters,)` respectively. It is recommended to benchmark each in the setting of interest to pick the most efficient one (in terms of speed and memory usage). Correct choice of implementation can lead to dramatic speed improvements (e.g. 50X), potentially at the expense of RAM. Also, only `padding=\"valid\"` is supported by `implementation=1`",
                "name": "implementation",
                "doc": "implementation mode, either `1`, `2`, or `3`. `1` loops over input spatial locations to perform the forward pass. It is memory-efficient but performs a lot of (small) ops. `2` stores layer weights in a dense but sparsely-populated 2D matrix and implements the forward pass as a single matrix-multiply. It uses a lot of RAM but performs few (large) ops. `3` stores layer weights in a sparse tensor and implements the forward pass as a single sparse matrix-multiply. How to choose: `1`: large, dense models, `2`: small models, `3`: large, sparse models, where \"large\" stands for large input/output activations (i.e. many `filters`, `input_filters`, large `np.prod(input_size)`, `np.prod(output_size)`), and \"sparse\" stands for few connections between inputs and outputs, i.e. small ratio `filters * input_filters * np.prod(kernel_size) / (np.prod(input_size) * np.prod(strides))`, where inputs to and outputs of the layer are assumed to have shapes `input_size + (input_filters,)`, `output_size + (filters,)` respectively. It is recommended to benchmark each in the setting of interest to pick the most efficient one (in terms of speed and memory usage). Correct choice of implementation can lead to dramatic speed improvements (e.g. 50X), potentially at the expense of RAM. Also, only `padding=\"valid\"` is supported by `implementation=1`"
            }
        ]
    },
    "Masking": {
        "multipleInputs": false,
        "doc": "Masks a sequence by using a mask value to skip timesteps\n",
        "altersShape": true,
        "params": [
            {
                "type": "Any",
                "name": "mask_value",
                "doc": "Any"
            }
        ]
    },
    "MaxPool1D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "pool_size",
                "doc": "Integer, size of the max pooling window"
            },
            {
                "type": "int",
                "name": "strides",
                "doc": "Integer, or None. Specifies how much the pooling window moves for each pooling step If None, it will default to `pool_size`"
            },
            {
                "type": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, steps, features)` while `channels_first` corresponds to inputs with shape `(batch, features, steps)`"
            }
        ]
    },
    "MaxPool2D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "tuple",
                "name": "pool_size",
                "doc": "integer or tuple of 2 integers, window size over which to take the maximum `(2, 2)` will take the max value over a 2x2 pooling window If only one integer is specified, the same window length will be used for both dimensions"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "Integer, tuple of 2 integers, or None Strides values. Specifies how far the pooling window moves for each pooling step. If None, it will default to `pool_size`"
            },
            {
                "type": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, height, width, channels)` while `channels_first` corresponds to inputs with shape `(batch, channels, height, width)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            }
        ]
    },
    "MaxPool3D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "tuple",
                "name": "pool_size",
                "doc": "Tuple of 3 integers, factors by which to downscale (dim1, dim2, dim3) `(2, 2, 2)` will halve the size of the 3D input in each dimension"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "tuple of 3 integers, or None. Strides values"
            },
            {
                "type": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)` while `channels_first` corresponds to inputs with shape `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            }
        ]
    },
    "MaxPooling1D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "pool_size",
                "doc": "Integer, size of the max pooling window"
            },
            {
                "type": "int",
                "name": "strides",
                "doc": "Integer, or None. Specifies how much the pooling window moves for each pooling step If None, it will default to `pool_size`"
            },
            {
                "type": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, steps, features)` while `channels_first` corresponds to inputs with shape `(batch, features, steps)`"
            }
        ]
    },
    "MaxPooling2D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "tuple",
                "name": "pool_size",
                "doc": "integer or tuple of 2 integers, window size over which to take the maximum `(2, 2)` will take the max value over a 2x2 pooling window If only one integer is specified, the same window length will be used for both dimensions"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "Integer, tuple of 2 integers, or None Strides values. Specifies how far the pooling window moves for each pooling step. If None, it will default to `pool_size`"
            },
            {
                "type": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, height, width, channels)` while `channels_first` corresponds to inputs with shape `(batch, channels, height, width)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            }
        ]
    },
    "MaxPooling3D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "tuple",
                "name": "pool_size",
                "doc": "Tuple of 3 integers, factors by which to downscale (dim1, dim2, dim3) `(2, 2, 2)` will halve the size of the 3D input in each dimension"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "tuple of 3 integers, or None. Strides values"
            },
            {
                "type": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "One of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)` while `channels_first` corresponds to inputs with shape `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            }
        ]
    },
    "Maximum": {
        "multipleInputs": false,
        "doc": "Layer that computes the maximum (element-wise) a list of inputs\n",
        "altersShape": true,
        "params": []
    },
    "Minimum": {
        "multipleInputs": false,
        "doc": "Layer that computes the minimum (element-wise) a list of inputs\n",
        "altersShape": true,
        "params": []
    },
    "MultiHeadAttention": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "Number of attention heads",
                "name": "num_heads",
                "doc": "Number of attention heads"
            },
            {
                "type": "Size of each attention head for query and key",
                "name": "key_dim",
                "doc": "Size of each attention head for query and key"
            },
            {
                "type": "Size of each attention head for value",
                "name": "value_dim",
                "doc": "Size of each attention head for value"
            },
            {
                "type": "Dropout probability",
                "name": "dropout",
                "doc": "Dropout probability"
            },
            {
                "type": "Boolean, whether the dense layers use bias vectors/matrices",
                "name": "use_bias",
                "doc": "Boolean, whether the dense layers use bias vectors/matrices"
            },
            {
                "type": "The expected shape of an output tensor, besides the batch and sequence dims. If not specified, projects back to the key feature dim",
                "name": "output_shape",
                "doc": "The expected shape of an output tensor, besides the batch and sequence dims. If not specified, projects back to the key feature dim"
            },
            {
                "type": "axes over which the attention is applied. `None` means attention over all axes, but batch, heads, and features",
                "name": "attention_axes",
                "doc": "axes over which the attention is applied. `None` means attention over all axes, but batch, heads, and features"
            },
            {
                "type": "Initializer for dense layer kernels",
                "name": "kernel_initializer",
                "doc": "Initializer for dense layer kernels"
            },
            {
                "type": "Initializer for dense layer biases",
                "name": "bias_initializer",
                "doc": "Initializer for dense layer biases"
            },
            {
                "type": "Regularizer for dense layer kernels",
                "name": "kernel_regularizer",
                "doc": "Regularizer for dense layer kernels"
            },
            {
                "type": "Regularizer for dense layer biases",
                "name": "bias_regularizer",
                "doc": "Regularizer for dense layer biases"
            },
            {
                "type": "Regularizer for dense layer activity",
                "name": "activity_regularizer",
                "doc": "Regularizer for dense layer activity"
            },
            {
                "type": "Constraint for dense layer kernels",
                "name": "kernel_constraint",
                "doc": "Constraint for dense layer kernels"
            },
            {
                "type": "Constraint for dense layer kernels",
                "name": "bias_constraint",
                "doc": "Constraint for dense layer kernels"
            }
        ]
    },
    "Multiply": {
        "multipleInputs": true,
        "doc": "Layer that multiplies (element-wise) a list of inputs\n",
        "altersShape": true,
        "params": []
    },
    "Normalization": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "axis",
                "doc": "Integer, tuple of integers, or None. The axis or axes that should have a separate mean and variance for each index in the shape. For example, if shape is `(None, 5)` and `axis=1`, the layer will track 5 separate mean and variance values for the last axis. If `axis` is set to `None`, the layer will normalize all elements in the input by a scalar mean and variance. Defaults to -1, where the last axis of the input is assumed to be a feature dimension and is normalized per index. Note that in the specific case of batched scalar inputs where the only axis is the batch axis, the default will normalize each index in the batch separately. In this case, consider passing `axis=None`"
            },
            {
                "type": "The mean value(s) to use during normalization. The passed value(s) will be broadcast to the shape of the kept axes above; if the value(s) cannot be broadcast, an error will be raised when this layer's `build()` method is called",
                "name": "mean",
                "doc": "The mean value(s) to use during normalization. The passed value(s) will be broadcast to the shape of the kept axes above; if the value(s) cannot be broadcast, an error will be raised when this layer's `build()` method is called"
            },
            {
                "type": "The variance value(s) to use during normalization. The passed value(s) will be broadcast to the shape of the kept axes above; if the value(s) cannot be broadcast, an error will be raised when this layer's `build()` method is called",
                "name": "variance",
                "doc": "The variance value(s) to use during normalization. The passed value(s) will be broadcast to the shape of the kept axes above; if the value(s) cannot be broadcast, an error will be raised when this layer's `build()` method is called"
            }
        ]
    },
    "PReLU": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "Initializer function for the weights",
                "name": "alpha_initializer",
                "doc": "Initializer function for the weights"
            },
            {
                "type": "Regularizer for the weights",
                "name": "alpha_regularizer",
                "doc": "Regularizer for the weights"
            },
            {
                "type": "Constraint for the weights",
                "name": "alpha_constraint",
                "doc": "Constraint for the weights"
            },
            {
                "type": "The axes along which to share learnable parameters for the activation function For example, if the incoming feature maps are from a 2D convolution with output shape `(batch, height, width, channels)`, and you wish to share parameters across space so that each filter only has one set of parameters, set `shared_axes=[1, 2]`",
                "name": "shared_axes",
                "doc": "The axes along which to share learnable parameters for the activation function For example, if the incoming feature maps are from a 2D convolution with output shape `(batch, height, width, channels)`, and you wish to share parameters across space so that each filter only has one set of parameters, set `shared_axes=[1, 2]`"
            }
        ]
    },
    "Permute": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "tuple",
                "name": "dims",
                "doc": "Tuple of integers. Permutation pattern does not include the samples dimension. Indexing starts at 1 For instance, `(2, 1)` permutes the first and second dimensions of the input"
            }
        ]
    },
    "RNN": {
        "multipleInputs": false,
        "doc": "zero_output_for_mask: Boolean (default `False`) Whether the output should use zeros for the masked timesteps. Note that this field is only used when `return_sequences` is True and mask is provided. It can useful if you want to reuse the raw output sequence of the RNN without interference from the masked timesteps, eg, merging bidirectional RNNs\n",
        "altersShape": true,
        "params": [
            {
                "type": "A RNN cell instance or a list of RNN cell instances A RNN cell is a class that has: - A `call(input_at_t, states_at_t)` method, returning `(output_at_t, states_at_t_plus_1)`. The call method of the cell can also take the optional argument `constants`, see section \"Note on passing external constants\" below - A `state_size` attribute. This can be a single integer (single state) in which case it is the size of the recurrent state. This can also be a list/tuple of integers (one size per state). The `state_size` can also be TensorShape or tuple/list of TensorShape, to represent high dimension state - A `output_size` attribute. This can be a single integer or a TensorShape, which represent the shape of the output. For backward compatible reason, if this attribute is not available for the cell, the value will be inferred by the first element of the `state_size` - A `get_initial_state(inputs=None, batch_size=None, dtype=None)` method that creates a tensor meant to be fed to `call()` as the initial state, if the user didn't specify any initial state via other means. The returned initial state should have a shape of [batch_size, cell.state_size]. The cell might choose to create a tensor full of zeros, or full of other values based on the cell's implementation. `inputs` is the input tensor to the RNN layer, which should contain the batch size as its shape[0], and also dtype. Note that the shape[0] might be `None` during the graph construction. Either the `inputs` or the pair of `batch_size` and `dtype` are provided. `batch_size` is a scalar tensor that represents the batch size of the inputs. `dtype` is `tf.DType` that represents the dtype of the inputs. For backward compatibility, if this method is not implemented by the cell, the RNN layer will create a zero filled tensor with the size of [batch_size, cell.state_size] In the case that `cell` is a list of RNN cell instances, the cells will be stacked on top of each other in the RNN, resulting in an efficient stacked RNN",
                "name": "cell",
                "doc": "A RNN cell instance or a list of RNN cell instances A RNN cell is a class that has: - A `call(input_at_t, states_at_t)` method, returning `(output_at_t, states_at_t_plus_1)`. The call method of the cell can also take the optional argument `constants`, see section \"Note on passing external constants\" below - A `state_size` attribute. This can be a single integer (single state) in which case it is the size of the recurrent state. This can also be a list/tuple of integers (one size per state). The `state_size` can also be TensorShape or tuple/list of TensorShape, to represent high dimension state - A `output_size` attribute. This can be a single integer or a TensorShape, which represent the shape of the output. For backward compatible reason, if this attribute is not available for the cell, the value will be inferred by the first element of the `state_size` - A `get_initial_state(inputs=None, batch_size=None, dtype=None)` method that creates a tensor meant to be fed to `call()` as the initial state, if the user didn't specify any initial state via other means. The returned initial state should have a shape of [batch_size, cell.state_size]. The cell might choose to create a tensor full of zeros, or full of other values based on the cell's implementation. `inputs` is the input tensor to the RNN layer, which should contain the batch size as its shape[0], and also dtype. Note that the shape[0] might be `None` during the graph construction. Either the `inputs` or the pair of `batch_size` and `dtype` are provided. `batch_size` is a scalar tensor that represents the batch size of the inputs. `dtype` is `tf.DType` that represents the dtype of the inputs. For backward compatibility, if this method is not implemented by the cell, the RNN layer will create a zero filled tensor with the size of [batch_size, cell.state_size] In the case that `cell` is a list of RNN cell instances, the cells will be stacked on top of each other in the RNN, resulting in an efficient stacked RNN"
            },
            {
                "type": "bool",
                "name": "return_sequences",
                "doc": "Boolean (default `False`). Whether to return the last output in the output sequence, or the full sequence"
            },
            {
                "type": "bool",
                "name": "return_state",
                "doc": "Boolean (default `False`). Whether to return the last state in addition to the output"
            },
            {
                "type": "bool",
                "name": "go_backwards",
                "doc": "Boolean (default `False`) If True, process the input sequence backwards and return the reversed sequence"
            },
            {
                "type": "bool",
                "name": "stateful",
                "doc": "Boolean (default `False`). If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch"
            },
            {
                "type": "bool",
                "name": "unroll",
                "doc": "Boolean (default `False`) If True, the network will be unrolled, else a symbolic loop will be used Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences"
            },
            {
                "type": "bool",
                "name": "time_major",
                "doc": "The shape format of the `inputs` and `outputs` tensors If True, the inputs and outputs will be in shape `(timesteps, batch, ...)`, whereas in the False case, it will be `(batch, timesteps, ...)`. Using `time_major = True` is a bit more efficient because it avoids transposes at the beginning and end of the RNN calculation. However, most TensorFlow data is batch-major, so by default this function accepts input and emits output in batch-major form"
            }
        ]
    },
    "RandomContrast": {
        "multipleInputs": false,
        "doc": "A preprocessing layer which randomly adjusts contrast during training\n",
        "altersShape": true,
        "params": [
            {
                "type": "Any",
                "name": "factor",
                "doc": "Any"
            },
            {
                "type": "int",
                "name": "seed",
                "doc": "Any"
            }
        ]
    },
    "RandomCrop": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "height",
                "doc": "Integer, the height of the output shape"
            },
            {
                "type": "int",
                "name": "width",
                "doc": "Integer, the width of the output shape"
            },
            {
                "type": "int",
                "name": "seed",
                "doc": "Integer. Used to create a random seed"
            }
        ]
    },
    "RandomFlip": {
        "multipleInputs": false,
        "doc": "A preprocessing layer which randomly flips images during training\n",
        "altersShape": true,
        "params": [
            {
                "type": "Any",
                "name": "mode",
                "doc": "Any"
            },
            {
                "type": "int",
                "name": "seed",
                "doc": "Any"
            }
        ]
    },
    "RandomHeight": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "float",
                "name": "factor",
                "doc": "A positive float (fraction of original height), or a tuple of size 2 representing lower and upper bound for resizing vertically. When represented as a single float, this value is used for both the upper and lower bound. For instance, `factor=(0.2, 0.3)` results in an output with height changed by a random amount in the range `[20%, 30%]` `factor=(-0.2, 0.3)` results in an output with height changed by a random amount in the range `[-20%, +30%]. `factor=0.2` results in an output with height changed by a random amount in the range `[-20%, +20%]`"
            },
            {
                "type": "String, the interpolation method. Defaults to `\"bilinear\"` Supports `\"bilinear\"`, `\"nearest\"`, `\"bicubic\"`, `\"area\"`, `\"lanczos3\"`, `\"lanczos5\"`, `\"gaussian\"`, `\"mitchellcubic\"`",
                "name": "interpolation",
                "doc": "String, the interpolation method. Defaults to `\"bilinear\"` Supports `\"bilinear\"`, `\"nearest\"`, `\"bicubic\"`, `\"area\"`, `\"lanczos3\"`, `\"lanczos5\"`, `\"gaussian\"`, `\"mitchellcubic\"`"
            },
            {
                "type": "int",
                "name": "seed",
                "doc": "Integer. Used to create a random seed"
            }
        ]
    },
    "RandomRotation": {
        "multipleInputs": false,
        "doc": "A preprocessing layer which randomly rotates images during training\n",
        "altersShape": true,
        "params": [
            {
                "type": "Any",
                "name": "factor",
                "doc": "Any"
            },
            {
                "type": "Any",
                "name": "fill_mode",
                "doc": "Any"
            },
            {
                "type": "Any",
                "name": "interpolation",
                "doc": "Any"
            },
            {
                "type": "int",
                "name": "seed",
                "doc": "Any"
            },
            {
                "type": "Any",
                "name": "fill_value",
                "doc": "Any"
            }
        ]
    },
    "RandomTranslation": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "float",
                "name": "height_factor",
                "doc": "a float represented as fraction of value, or a tuple of size 2 representing lower and upper bound for shifting vertically. A negative value means shifting image up, while a positive value means shifting image down. When represented as a single positive float, this value is used for both the upper and lower bound. For instance, `height_factor=(-0.2, 0.3)` results in an output shifted by a random amount in the range `[-20%, +30%]` `height_factor=0.2` results in an output height shifted by a random amount in the range `[-20%, +20%]`"
            },
            {
                "type": "float",
                "name": "width_factor",
                "doc": "a float represented as fraction of value, or a tuple of size 2 representing lower and upper bound for shifting horizontally. A negative value means shifting image left, while a positive value means shifting image right. When represented as a single positive float, this value is used for both the upper and lower bound. For instance, `width_factor=(-0.2, 0.3)` results in an output shifted left by 20%, and shifted right by 30%. `width_factor=0.2` results in an output height shifted left or right by 20%"
            },
            {
                "type": "tuple",
                "name": "fill_mode",
                "doc": "Points outside the boundaries of the input are filled according to the given mode (one of `{\"constant\", \"reflect\", \"wrap\", \"nearest\"}`) - *reflect*: `(d c b a | a b c d | d c b a)` The input is extended by reflecting about the edge of the last pixel - *constant*: `(k k k k | a b c d | k k k k)` The input is extended by filling all values beyond the edge with the same constant value k = 0 - *wrap*: `(a b c d | a b c d | a b c d)` The input is extended by wrapping around to the opposite edge - *nearest*: `(a a a a | a b c d | d d d d)` The input is extended by the nearest pixel"
            },
            {
                "type": "Interpolation mode. Supported values: `\"nearest\"`, `\"bilinear\"`",
                "name": "interpolation",
                "doc": "Interpolation mode. Supported values: `\"nearest\"`, `\"bilinear\"`"
            },
            {
                "type": "int",
                "name": "seed",
                "doc": "Integer. Used to create a random seed"
            },
            {
                "type": "float",
                "name": "fill_value",
                "doc": "a float represents the value to be filled outside the boundaries when `fill_mode=\"constant\"`"
            }
        ]
    },
    "RandomWidth": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "float",
                "name": "factor",
                "doc": "A positive float (fraction of original width), or a tuple of size 2 representing lower and upper bound for resizing vertically. When represented as a single float, this value is used for both the upper and lower bound. For instance, `factor=(0.2, 0.3)` results in an output with width changed by a random amount in the range `[20%, 30%]`. `factor=(-0.2, 0.3)` results in an output with width changed by a random amount in the range `[-20%, +30%]`. `factor=0.2` results in an output with width changed by a random amount in the range `[-20%, +20%]`"
            },
            {
                "type": "String, the interpolation method. Defaults to `bilinear` Supports `\"bilinear\"`, `\"nearest\"`, `\"bicubic\"`, `\"area\"`, `\"lanczos3\"`, `\"lanczos5\"`, `\"gaussian\"`, `\"mitchellcubic\"`",
                "name": "interpolation",
                "doc": "String, the interpolation method. Defaults to `bilinear` Supports `\"bilinear\"`, `\"nearest\"`, `\"bicubic\"`, `\"area\"`, `\"lanczos3\"`, `\"lanczos5\"`, `\"gaussian\"`, `\"mitchellcubic\"`"
            },
            {
                "type": "int",
                "name": "seed",
                "doc": "Integer. Used to create a random seed"
            }
        ]
    },
    "RandomZoom": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "float",
                "name": "height_factor",
                "doc": "a float represented as fraction of value, or a tuple of size 2 representing lower and upper bound for zooming vertically. When represented as a single float, this value is used for both the upper and lower bound. A positive value means zooming out, while a negative value means zooming in. For instance, `height_factor=(0.2, 0.3)` result in an output zoomed out by a random amount in the range `[+20%, +30%]` `height_factor=(-0.3, -0.2)` result in an output zoomed in by a random amount in the range `[+20%, +30%]`"
            },
            {
                "type": "float",
                "name": "width_factor",
                "doc": "a float represented as fraction of value, or a tuple of size 2 representing lower and upper bound for zooming horizontally. When represented as a single float, this value is used for both the upper and lower bound. For instance, `width_factor=(0.2, 0.3)` result in an output zooming out between 20% to 30%. `width_factor=(-0.3, -0.2)` result in an output zooming in between 20% to 30%. Defaults to `None`, i.e., zooming vertical and horizontal directions by preserving the aspect ratio"
            },
            {
                "type": "tuple",
                "name": "fill_mode",
                "doc": "Points outside the boundaries of the input are filled according to the given mode (one of `{\"constant\", \"reflect\", \"wrap\", \"nearest\"}`) - *reflect*: `(d c b a | a b c d | d c b a)` The input is extended by reflecting about the edge of the last pixel - *constant*: `(k k k k | a b c d | k k k k)` The input is extended by filling all values beyond the edge with the same constant value k = 0 - *wrap*: `(a b c d | a b c d | a b c d)` The input is extended by wrapping around to the opposite edge - *nearest*: `(a a a a | a b c d | d d d d)` The input is extended by the nearest pixel"
            },
            {
                "type": "Interpolation mode. Supported values: `\"nearest\"`, `\"bilinear\"`",
                "name": "interpolation",
                "doc": "Interpolation mode. Supported values: `\"nearest\"`, `\"bilinear\"`"
            },
            {
                "type": "int",
                "name": "seed",
                "doc": "Integer. Used to create a random seed"
            },
            {
                "type": "float",
                "name": "fill_value",
                "doc": "a float represents the value to be filled outside the boundaries when `fill_mode=\"constant\"`"
            }
        ]
    },
    "ReLU": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "float",
                "name": "max_value",
                "doc": "Float >= 0. Maximum activation value. Default to None, which means unlimited"
            },
            {
                "type": "float",
                "name": "negative_slope",
                "doc": "Float >= 0. Negative slope coefficient. Default to 0"
            },
            {
                "type": "float",
                "name": "threshold",
                "doc": "Float >= 0. Threshold value for thresholded activation. Default to 0"
            }
        ]
    },
    "RepeatVector": {
        "multipleInputs": false,
        "doc": "Input shape: 2D tensor of shape `(num_samples, features)`\nOutput shape: 3D tensor of shape `(num_samples, n, features)`\n",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "n",
                "doc": "Integer, repetition factor"
            }
        ]
    },
    "Rescaling": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "float",
                "name": "scale",
                "doc": "Float, the scale to apply to the inputs"
            },
            {
                "type": "float",
                "name": "offset",
                "doc": "Float, the offset to apply to the inputs"
            }
        ]
    },
    "Reshape": {
        "multipleInputs": false,
        "doc": "Layer that reshapes inputs into the given shape\n",
        "altersShape": true,
        "params": [
            {
                "type": "Any",
                "name": "target_shape",
                "doc": "Any"
            }
        ]
    },
    "Resizing": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "height",
                "doc": "Integer, the height of the output shape"
            },
            {
                "type": "int",
                "name": "width",
                "doc": "Integer, the width of the output shape"
            },
            {
                "type": "String, the interpolation method. Defaults to `\"bilinear\"` Supports `\"bilinear\"`, `\"nearest\"`, `\"bicubic\"`, `\"area\"`, `\"lanczos3\"`, `\"lanczos5\"`, `\"gaussian\"`, `\"mitchellcubic\"`",
                "name": "interpolation",
                "doc": "String, the interpolation method. Defaults to `\"bilinear\"` Supports `\"bilinear\"`, `\"nearest\"`, `\"bicubic\"`, `\"area\"`, `\"lanczos3\"`, `\"lanczos5\"`, `\"gaussian\"`, `\"mitchellcubic\"`"
            },
            {
                "type": "bool",
                "name": "crop_to_aspect_ratio",
                "doc": "If True, resize the images without aspect ratio distortion. When the original aspect ratio differs from the target aspect ratio, the output image will be cropped so as to return the largest possible window in the image (of size `(height, width)`) that matches the target aspect ratio. By default (`crop_to_aspect_ratio=False`), aspect ratio may not be preserved"
            }
        ]
    },
    "SeparableConv1D": {
        "multipleInputs": false,
        "doc": "trainable: Boolean, if `True` the weights of this layer will be marked as trainable (and listed in `layer.trainable_weights`)\n",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "filters",
                "doc": "Integer, the dimensionality of the output space (i.e. the number of filters in the convolution)"
            },
            {
                "type": "int",
                "name": "kernel_size",
                "doc": "A single integer specifying the spatial dimensions of the filters"
            },
            {
                "type": "int",
                "name": "strides",
                "doc": "A single integer specifying the strides of the convolution Specifying any `stride` value != 1 is incompatible with specifying any `dilation_rate` value != 1"
            },
            {
                "type": "One of `\"valid\"`, `\"same\"`, or `\"causal\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input. `\"causal\"` results in causal (dilated) convolutions, e.g. `output[t]` does not depend on `input[t+1:]`",
                "name": "padding",
                "doc": "One of `\"valid\"`, `\"same\"`, or `\"causal\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input. `\"causal\"` results in causal (dilated) convolutions, e.g. `output[t]` does not depend on `input[t+1:]`"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch_size, length, channels)` while `channels_first` corresponds to inputs with shape `(batch_size, channels, length)`"
            },
            {
                "type": "int",
                "name": "dilation_rate",
                "doc": "A single integer, specifying the dilation rate to use for dilated convolution"
            },
            {
                "type": "The number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to `num_filters_in * depth_multiplier`",
                "name": "depth_multiplier",
                "doc": "The number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to `num_filters_in * depth_multiplier`"
            },
            {
                "type": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)",
                "name": "activation",
                "doc": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)"
            },
            {
                "type": "Boolean, whether the layer uses a bias",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias"
            },
            {
                "type": "An initializer for the depthwise convolution kernel (see `keras.initializers`). If None, then the default initializer ('glorot_uniform') will be used",
                "name": "depthwise_initializer",
                "doc": "An initializer for the depthwise convolution kernel (see `keras.initializers`). If None, then the default initializer ('glorot_uniform') will be used"
            },
            {
                "type": "An initializer for the pointwise convolution kernel (see `keras.initializers`). If None, then the default initializer ('glorot_uniform') will be used",
                "name": "pointwise_initializer",
                "doc": "An initializer for the pointwise convolution kernel (see `keras.initializers`). If None, then the default initializer ('glorot_uniform') will be used"
            },
            {
                "type": "An initializer for the bias vector. If None, the default initializer ('zeros') will be used (see `keras.initializers`)",
                "name": "bias_initializer",
                "doc": "An initializer for the bias vector. If None, the default initializer ('zeros') will be used (see `keras.initializers`)"
            },
            {
                "type": "Optional regularizer for the depthwise convolution kernel (see `keras.regularizers`)",
                "name": "depthwise_regularizer",
                "doc": "Optional regularizer for the depthwise convolution kernel (see `keras.regularizers`)"
            },
            {
                "type": "Optional regularizer for the pointwise convolution kernel (see `keras.regularizers`)",
                "name": "pointwise_regularizer",
                "doc": "Optional regularizer for the pointwise convolution kernel (see `keras.regularizers`)"
            },
            {
                "type": "Optional regularizer for the bias vector (see `keras.regularizers`)",
                "name": "bias_regularizer",
                "doc": "Optional regularizer for the bias vector (see `keras.regularizers`)"
            },
            {
                "type": "Optional regularizer function for the output (see `keras.regularizers`)",
                "name": "activity_regularizer",
                "doc": "Optional regularizer function for the output (see `keras.regularizers`)"
            },
            {
                "type": "Optional projection function to be applied to the depthwise kernel after being updated by an `Optimizer` (e.g. used for norm constraints or value constraints for layer weights). The function must take as input the unprojected variable and must return the projected variable (which must have the same shape). Constraints are not safe to use when doing asynchronous distributed training (see `keras.constraints`)",
                "name": "depthwise_constraint",
                "doc": "Optional projection function to be applied to the depthwise kernel after being updated by an `Optimizer` (e.g. used for norm constraints or value constraints for layer weights). The function must take as input the unprojected variable and must return the projected variable (which must have the same shape). Constraints are not safe to use when doing asynchronous distributed training (see `keras.constraints`)"
            },
            {
                "type": "Optional projection function to be applied to the pointwise kernel after being updated by an `Optimizer` (see `keras.constraints`)",
                "name": "pointwise_constraint",
                "doc": "Optional projection function to be applied to the pointwise kernel after being updated by an `Optimizer` (see `keras.constraints`)"
            },
            {
                "type": "Optional projection function to be applied to the bias after being updated by an `Optimizer` (see `keras.constraints`)",
                "name": "bias_constraint",
                "doc": "Optional projection function to be applied to the bias after being updated by an `Optimizer` (see `keras.constraints`)"
            }
        ]
    },
    "SeparableConv2D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "filters",
                "doc": "Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution)"
            },
            {
                "type": "tuple",
                "name": "kernel_size",
                "doc": "An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window Can be a single integer to specify the same value for all spatial dimensions"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width Can be a single integer to specify the same value for all spatial dimensions. Current implementation only supports equal length strides in the row and column dimensions Specifying any stride value != 1 is incompatible with specifying any `dilation_rate` value != 1"
            },
            {
                "type": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch_size, height, width, channels)` while `channels_first` corresponds to inputs with shape `(batch_size, channels, height, width)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "tuple",
                "name": "dilation_rate",
                "doc": "An integer or tuple/list of 2 integers, specifying the dilation rate to use for dilated convolution"
            },
            {
                "type": "The number of depthwise convolution output channels for each input channel The total number of depthwise convolution output channels will be equal to `filters_in * depth_multiplier`",
                "name": "depth_multiplier",
                "doc": "The number of depthwise convolution output channels for each input channel The total number of depthwise convolution output channels will be equal to `filters_in * depth_multiplier`"
            },
            {
                "type": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)",
                "name": "activation",
                "doc": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)"
            },
            {
                "type": "Boolean, whether the layer uses a bias vector",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias vector"
            },
            {
                "type": "An initializer for the depthwise convolution kernel (see `keras.initializers`). If None, then the default initializer ('glorot_uniform') will be used",
                "name": "depthwise_initializer",
                "doc": "An initializer for the depthwise convolution kernel (see `keras.initializers`). If None, then the default initializer ('glorot_uniform') will be used"
            },
            {
                "type": "An initializer for the pointwise convolution kernel (see `keras.initializers`). If None, then the default initializer ('glorot_uniform') will be used",
                "name": "pointwise_initializer",
                "doc": "An initializer for the pointwise convolution kernel (see `keras.initializers`). If None, then the default initializer ('glorot_uniform') will be used"
            },
            {
                "type": "An initializer for the bias vector. If None, the default initializer ('zeros') will be used (see `keras.initializers`)",
                "name": "bias_initializer",
                "doc": "An initializer for the bias vector. If None, the default initializer ('zeros') will be used (see `keras.initializers`)"
            },
            {
                "type": "Regularizer function applied to the depthwise kernel matrix (see `keras.regularizers`)",
                "name": "depthwise_regularizer",
                "doc": "Regularizer function applied to the depthwise kernel matrix (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the pointwise kernel matrix (see `keras.regularizers`)",
                "name": "pointwise_regularizer",
                "doc": "Regularizer function applied to the pointwise kernel matrix (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the bias vector (see `keras.regularizers`)",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)"
            },
            {
                "type": "Constraint function applied to the depthwise kernel matrix (see `keras.constraints`)",
                "name": "depthwise_constraint",
                "doc": "Constraint function applied to the depthwise kernel matrix (see `keras.constraints`)"
            },
            {
                "type": "Constraint function applied to the pointwise kernel matrix (see `keras.constraints`)",
                "name": "pointwise_constraint",
                "doc": "Constraint function applied to the pointwise kernel matrix (see `keras.constraints`)"
            },
            {
                "type": "Constraint function applied to the bias vector (see `keras.constraints`)",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector (see `keras.constraints`)"
            }
        ]
    },
    "SeparableConvolution1D": {
        "multipleInputs": false,
        "doc": "trainable: Boolean, if `True` the weights of this layer will be marked as trainable (and listed in `layer.trainable_weights`)\n",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "filters",
                "doc": "Integer, the dimensionality of the output space (i.e. the number of filters in the convolution)"
            },
            {
                "type": "int",
                "name": "kernel_size",
                "doc": "A single integer specifying the spatial dimensions of the filters"
            },
            {
                "type": "int",
                "name": "strides",
                "doc": "A single integer specifying the strides of the convolution Specifying any `stride` value != 1 is incompatible with specifying any `dilation_rate` value != 1"
            },
            {
                "type": "One of `\"valid\"`, `\"same\"`, or `\"causal\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input. `\"causal\"` results in causal (dilated) convolutions, e.g. `output[t]` does not depend on `input[t+1:]`",
                "name": "padding",
                "doc": "One of `\"valid\"`, `\"same\"`, or `\"causal\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input. `\"causal\"` results in causal (dilated) convolutions, e.g. `output[t]` does not depend on `input[t+1:]`"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch_size, length, channels)` while `channels_first` corresponds to inputs with shape `(batch_size, channels, length)`"
            },
            {
                "type": "int",
                "name": "dilation_rate",
                "doc": "A single integer, specifying the dilation rate to use for dilated convolution"
            },
            {
                "type": "The number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to `num_filters_in * depth_multiplier`",
                "name": "depth_multiplier",
                "doc": "The number of depthwise convolution output channels for each input channel. The total number of depthwise convolution output channels will be equal to `num_filters_in * depth_multiplier`"
            },
            {
                "type": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)",
                "name": "activation",
                "doc": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)"
            },
            {
                "type": "Boolean, whether the layer uses a bias",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias"
            },
            {
                "type": "An initializer for the depthwise convolution kernel (see `keras.initializers`). If None, then the default initializer ('glorot_uniform') will be used",
                "name": "depthwise_initializer",
                "doc": "An initializer for the depthwise convolution kernel (see `keras.initializers`). If None, then the default initializer ('glorot_uniform') will be used"
            },
            {
                "type": "An initializer for the pointwise convolution kernel (see `keras.initializers`). If None, then the default initializer ('glorot_uniform') will be used",
                "name": "pointwise_initializer",
                "doc": "An initializer for the pointwise convolution kernel (see `keras.initializers`). If None, then the default initializer ('glorot_uniform') will be used"
            },
            {
                "type": "An initializer for the bias vector. If None, the default initializer ('zeros') will be used (see `keras.initializers`)",
                "name": "bias_initializer",
                "doc": "An initializer for the bias vector. If None, the default initializer ('zeros') will be used (see `keras.initializers`)"
            },
            {
                "type": "Optional regularizer for the depthwise convolution kernel (see `keras.regularizers`)",
                "name": "depthwise_regularizer",
                "doc": "Optional regularizer for the depthwise convolution kernel (see `keras.regularizers`)"
            },
            {
                "type": "Optional regularizer for the pointwise convolution kernel (see `keras.regularizers`)",
                "name": "pointwise_regularizer",
                "doc": "Optional regularizer for the pointwise convolution kernel (see `keras.regularizers`)"
            },
            {
                "type": "Optional regularizer for the bias vector (see `keras.regularizers`)",
                "name": "bias_regularizer",
                "doc": "Optional regularizer for the bias vector (see `keras.regularizers`)"
            },
            {
                "type": "Optional regularizer function for the output (see `keras.regularizers`)",
                "name": "activity_regularizer",
                "doc": "Optional regularizer function for the output (see `keras.regularizers`)"
            },
            {
                "type": "Optional projection function to be applied to the depthwise kernel after being updated by an `Optimizer` (e.g. used for norm constraints or value constraints for layer weights). The function must take as input the unprojected variable and must return the projected variable (which must have the same shape). Constraints are not safe to use when doing asynchronous distributed training (see `keras.constraints`)",
                "name": "depthwise_constraint",
                "doc": "Optional projection function to be applied to the depthwise kernel after being updated by an `Optimizer` (e.g. used for norm constraints or value constraints for layer weights). The function must take as input the unprojected variable and must return the projected variable (which must have the same shape). Constraints are not safe to use when doing asynchronous distributed training (see `keras.constraints`)"
            },
            {
                "type": "Optional projection function to be applied to the pointwise kernel after being updated by an `Optimizer` (see `keras.constraints`)",
                "name": "pointwise_constraint",
                "doc": "Optional projection function to be applied to the pointwise kernel after being updated by an `Optimizer` (see `keras.constraints`)"
            },
            {
                "type": "Optional projection function to be applied to the bias after being updated by an `Optimizer` (see `keras.constraints`)",
                "name": "bias_constraint",
                "doc": "Optional projection function to be applied to the bias after being updated by an `Optimizer` (see `keras.constraints`)"
            }
        ]
    },
    "SeparableConvolution2D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "filters",
                "doc": "Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution)"
            },
            {
                "type": "tuple",
                "name": "kernel_size",
                "doc": "An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window Can be a single integer to specify the same value for all spatial dimensions"
            },
            {
                "type": "tuple",
                "name": "strides",
                "doc": "An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width Can be a single integer to specify the same value for all spatial dimensions. Current implementation only supports equal length strides in the row and column dimensions Specifying any stride value != 1 is incompatible with specifying any `dilation_rate` value != 1"
            },
            {
                "type": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input",
                "name": "padding",
                "doc": "one of `\"valid\"` or `\"same\"` (case-insensitive) `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch_size, height, width, channels)` while `channels_first` corresponds to inputs with shape `(batch_size, channels, height, width)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "tuple",
                "name": "dilation_rate",
                "doc": "An integer or tuple/list of 2 integers, specifying the dilation rate to use for dilated convolution"
            },
            {
                "type": "The number of depthwise convolution output channels for each input channel The total number of depthwise convolution output channels will be equal to `filters_in * depth_multiplier`",
                "name": "depth_multiplier",
                "doc": "The number of depthwise convolution output channels for each input channel The total number of depthwise convolution output channels will be equal to `filters_in * depth_multiplier`"
            },
            {
                "type": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)",
                "name": "activation",
                "doc": "Activation function to use If you don't specify anything, no activation is applied (see `keras.activations`)"
            },
            {
                "type": "Boolean, whether the layer uses a bias vector",
                "name": "use_bias",
                "doc": "Boolean, whether the layer uses a bias vector"
            },
            {
                "type": "An initializer for the depthwise convolution kernel (see `keras.initializers`). If None, then the default initializer ('glorot_uniform') will be used",
                "name": "depthwise_initializer",
                "doc": "An initializer for the depthwise convolution kernel (see `keras.initializers`). If None, then the default initializer ('glorot_uniform') will be used"
            },
            {
                "type": "An initializer for the pointwise convolution kernel (see `keras.initializers`). If None, then the default initializer ('glorot_uniform') will be used",
                "name": "pointwise_initializer",
                "doc": "An initializer for the pointwise convolution kernel (see `keras.initializers`). If None, then the default initializer ('glorot_uniform') will be used"
            },
            {
                "type": "An initializer for the bias vector. If None, the default initializer ('zeros') will be used (see `keras.initializers`)",
                "name": "bias_initializer",
                "doc": "An initializer for the bias vector. If None, the default initializer ('zeros') will be used (see `keras.initializers`)"
            },
            {
                "type": "Regularizer function applied to the depthwise kernel matrix (see `keras.regularizers`)",
                "name": "depthwise_regularizer",
                "doc": "Regularizer function applied to the depthwise kernel matrix (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the pointwise kernel matrix (see `keras.regularizers`)",
                "name": "pointwise_regularizer",
                "doc": "Regularizer function applied to the pointwise kernel matrix (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the bias vector (see `keras.regularizers`)",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector (see `keras.regularizers`)"
            },
            {
                "type": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to the output of the layer (its \"activation\") (see `keras.regularizers`)"
            },
            {
                "type": "Constraint function applied to the depthwise kernel matrix (see `keras.constraints`)",
                "name": "depthwise_constraint",
                "doc": "Constraint function applied to the depthwise kernel matrix (see `keras.constraints`)"
            },
            {
                "type": "Constraint function applied to the pointwise kernel matrix (see `keras.constraints`)",
                "name": "pointwise_constraint",
                "doc": "Constraint function applied to the pointwise kernel matrix (see `keras.constraints`)"
            },
            {
                "type": "Constraint function applied to the bias vector (see `keras.constraints`)",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector (see `keras.constraints`)"
            }
        ]
    },
    "SimpleRNN": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "units",
                "doc": "Positive integer, dimensionality of the output space"
            },
            {
                "type": "Activation function to use Default: hyperbolic tangent (`tanh`) If you pass None, no activation is applied (ie. \"linear\" activation: `a(x) = x`)",
                "name": "activation",
                "doc": "Activation function to use Default: hyperbolic tangent (`tanh`) If you pass None, no activation is applied (ie. \"linear\" activation: `a(x) = x`)"
            },
            {
                "type": "bool",
                "name": "use_bias",
                "doc": "Boolean, (default `True`), whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs. Default: `glorot_uniform`",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs. Default: `glorot_uniform`"
            },
            {
                "type": "Initializer for the `recurrent_kernel` weights matrix, used for the linear transformation of the recurrent state Default: `orthogonal`",
                "name": "recurrent_initializer",
                "doc": "Initializer for the `recurrent_kernel` weights matrix, used for the linear transformation of the recurrent state Default: `orthogonal`"
            },
            {
                "type": "Initializer for the bias vector. Default: `zeros`",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector. Default: `zeros`"
            },
            {
                "type": "Regularizer function applied to the `kernel` weights matrix. Default: `None`",
                "name": "kernel_regularizer",
                "doc": "Regularizer function applied to the `kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Regularizer function applied to the `recurrent_kernel` weights matrix. Default: `None`",
                "name": "recurrent_regularizer",
                "doc": "Regularizer function applied to the `recurrent_kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Regularizer function applied to the bias vector. Default: `None`",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector. Default: `None`"
            },
            {
                "type": "Regularizer function applied to the output of the layer (its \"activation\"). Default: `None`",
                "name": "activity_regularizer",
                "doc": "Regularizer function applied to the output of the layer (its \"activation\"). Default: `None`"
            },
            {
                "type": "Constraint function applied to the `kernel` weights matrix. Default: `None`",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the `kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Constraint function applied to the `recurrent_kernel` weights matrix. Default: `None`",
                "name": "recurrent_constraint",
                "doc": "Constraint function applied to the `recurrent_kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Constraint function applied to the bias vector. Default: `None`",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector. Default: `None`"
            },
            {
                "type": "float",
                "name": "dropout",
                "doc": "Float between 0 and 1 Fraction of the units to drop for the linear transformation of the inputs Default: 0"
            },
            {
                "type": "float",
                "name": "recurrent_dropout",
                "doc": "Float between 0 and 1 Fraction of the units to drop for the linear transformation of the recurrent state. Default: 0"
            },
            {
                "type": "bool",
                "name": "return_sequences",
                "doc": "Boolean. Whether to return the last output in the output sequence, or the full sequence. Default: `False`"
            },
            {
                "type": "bool",
                "name": "return_state",
                "doc": "Boolean. Whether to return the last state in addition to the output. Default: `False` go_backwards: Boolean (default False) If True, process the input sequence backwards and return the reversed sequence"
            },
            {
                "type": "Any",
                "name": "go_backwards",
                "doc": "Any"
            },
            {
                "type": "bool",
                "name": "stateful",
                "doc": "Boolean (default False). If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch"
            },
            {
                "type": "bool",
                "name": "unroll",
                "doc": "Boolean (default False) If True, the network will be unrolled, else a symbolic loop will be used Unrolling can speed-up a RNN, although it tends to be more memory-intensive Unrolling is only suitable for short sequences"
            }
        ]
    },
    "SimpleRNNCell": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "units",
                "doc": "Positive integer, dimensionality of the output space"
            },
            {
                "type": "Activation function to use Default: hyperbolic tangent (`tanh`) If you pass `None`, no activation is applied (ie. \"linear\" activation: `a(x) = x`)",
                "name": "activation",
                "doc": "Activation function to use Default: hyperbolic tangent (`tanh`) If you pass `None`, no activation is applied (ie. \"linear\" activation: `a(x) = x`)"
            },
            {
                "type": "bool",
                "name": "use_bias",
                "doc": "Boolean, (default `True`), whether the layer uses a bias vector"
            },
            {
                "type": "Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs. Default: `glorot_uniform`",
                "name": "kernel_initializer",
                "doc": "Initializer for the `kernel` weights matrix, used for the linear transformation of the inputs. Default: `glorot_uniform`"
            },
            {
                "type": "Initializer for the `recurrent_kernel` weights matrix, used for the linear transformation of the recurrent state Default: `orthogonal`",
                "name": "recurrent_initializer",
                "doc": "Initializer for the `recurrent_kernel` weights matrix, used for the linear transformation of the recurrent state Default: `orthogonal`"
            },
            {
                "type": "Initializer for the bias vector. Default: `zeros`",
                "name": "bias_initializer",
                "doc": "Initializer for the bias vector. Default: `zeros`"
            },
            {
                "type": "Regularizer function applied to the `kernel` weights matrix. Default: `None`",
                "name": "kernel_regularizer",
                "doc": "Regularizer function applied to the `kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Regularizer function applied to the `recurrent_kernel` weights matrix. Default: `None`",
                "name": "recurrent_regularizer",
                "doc": "Regularizer function applied to the `recurrent_kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Regularizer function applied to the bias vector. Default: `None`",
                "name": "bias_regularizer",
                "doc": "Regularizer function applied to the bias vector. Default: `None`"
            },
            {
                "type": "Constraint function applied to the `kernel` weights matrix. Default: `None`",
                "name": "kernel_constraint",
                "doc": "Constraint function applied to the `kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Constraint function applied to the `recurrent_kernel` weights matrix. Default: `None`",
                "name": "recurrent_constraint",
                "doc": "Constraint function applied to the `recurrent_kernel` weights matrix. Default: `None`"
            },
            {
                "type": "Constraint function applied to the bias vector. Default: `None`",
                "name": "bias_constraint",
                "doc": "Constraint function applied to the bias vector. Default: `None`"
            },
            {
                "type": "float",
                "name": "dropout",
                "doc": "Float between 0 and 1. Fraction of the units to drop for the linear transformation of the inputs. Default: 0"
            },
            {
                "type": "float",
                "name": "recurrent_dropout",
                "doc": "Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state. Default: 0"
            }
        ]
    },
    "Softmax": {
        "multipleInputs": false,
        "doc": "Call arguments: inputs: The inputs, or logits to the softmax layer\nmask: A boolean mask of the same shape as `inputs`. Defaults to `None`. The mask specifies 1 to keep and 0 to mask\n",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "axis",
                "doc": "Integer, or list of Integers, axis along which the softmax normalization is applied"
            }
        ]
    },
    "SpatialDropout1D": {
        "multipleInputs": false,
        "doc": "Call arguments: inputs: A 3D tensor\ntraining: Python boolean indicating whether the layer should behave in training mode (adding dropout) or in inference mode (doing nothing)\nInput shape: 3D tensor with shape: `(samples, timesteps, channels)` Output shape: Same as input\nReferences: - [Efficient Object Localization Using Convolutional Networks](https://arxiv.org/abs/1411.4280)\n",
        "altersShape": true,
        "params": [
            {
                "type": "float",
                "name": "rate",
                "doc": "Float between 0 and 1. Fraction of the input units to drop"
            }
        ]
    },
    "SpatialDropout2D": {
        "multipleInputs": false,
        "doc": "Call arguments: inputs: A 4D tensor\ntraining: Python boolean indicating whether the layer should behave in training mode (adding dropout) or in inference mode (doing nothing)\nInput shape: 4D tensor with shape: `(samples, channels, rows, cols)` if data_format='channels_first' or 4D tensor with shape: `(samples, rows, cols, channels)` if data_format='channels_last'\nOutput shape: Same as input\nReferences: - [Efficient Object Localization Using Convolutional Networks](https://arxiv.org/abs/1411.4280)\n",
        "altersShape": true,
        "params": [
            {
                "type": "float",
                "name": "rate",
                "doc": "Float between 0 and 1. Fraction of the input units to drop"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension (the depth) is at index 1, in 'channels_last' mode is it at index 3. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be \"channels_last\""
            }
        ]
    },
    "SpatialDropout3D": {
        "multipleInputs": false,
        "doc": "Call arguments: inputs: A 5D tensor\ntraining: Python boolean indicating whether the layer should behave in training mode (adding dropout) or in inference mode (doing nothing)\nInput shape: 5D tensor with shape: `(samples, channels, dim1, dim2, dim3)` if data_format='channels_first' or 5D tensor with shape: `(samples, dim1, dim2, dim3, channels)` if data_format='channels_last'\nOutput shape: Same as input\nReferences: - [Efficient Object Localization Using Convolutional Networks](https://arxiv.org/abs/1411.4280)\n",
        "altersShape": true,
        "params": [
            {
                "type": "float",
                "name": "rate",
                "doc": "Float between 0 and 1. Fraction of the input units to drop"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "'channels_first' or 'channels_last'. In 'channels_first' mode, the channels dimension (the depth) is at index 1, in 'channels_last' mode is it at index 4. It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json`. If you never set it, then it will be \"channels_last\""
            }
        ]
    },
    "StackedRNNCells": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "List of RNN cell instances",
                "name": "cells",
                "doc": "List of RNN cell instances"
            }
        ]
    },
    "StringLookup": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "bool",
                "name": "max_tokens",
                "doc": "Maximum size of the vocabulary for this layer. This should only be specified when adapting the vocabulary or when setting `pad_to_max_tokens=True`. If None, there is no cap on the size of the vocabulary. Note that this size includes the OOV and mask tokens. Defaults to None"
            },
            {
                "type": "The number of out-of-vocabulary tokens to use. If this value is more than 1, OOV inputs are hashed to determine their OOV value If this value is 0, OOV inputs will cause an error when calling the layer Defaults to 1",
                "name": "num_oov_indices",
                "doc": "The number of out-of-vocabulary tokens to use. If this value is more than 1, OOV inputs are hashed to determine their OOV value If this value is 0, OOV inputs will cause an error when calling the layer Defaults to 1"
            },
            {
                "type": "A token that represents masked inputs. When `output_mode` is `\"int\"`, the token is included in vocabulary and mapped to index 0. In other output modes, the token will not appear in the vocabulary and instances of the mask token in the input will be dropped. If set to None, no mask term will be added. Defaults to `None`",
                "name": "mask_token",
                "doc": "A token that represents masked inputs. When `output_mode` is `\"int\"`, the token is included in vocabulary and mapped to index 0. In other output modes, the token will not appear in the vocabulary and instances of the mask token in the input will be dropped. If set to None, no mask term will be added. Defaults to `None`"
            },
            {
                "type": "bool",
                "name": "oov_token",
                "doc": "Only used when `invert` is True. The token to return for OOV indices. Defaults to `\"[UNK]\"`"
            },
            {
                "type": "Optional. Either an array of strings or a string path to a text file. If passing an array, can pass a tuple, list, 1D numpy array, or 1D tensor containing the string vocbulary terms. If passing a file path, the file should contain one line per term in the vocabulary. If this argument is set, there is no need to `adapt()` the layer",
                "name": "vocabulary",
                "doc": "Optional. Either an array of strings or a string path to a text file. If passing an array, can pass a tuple, list, 1D numpy array, or 1D tensor containing the string vocbulary terms. If passing a file path, the file should contain one line per term in the vocabulary. If this argument is set, there is no need to `adapt()` the layer"
            },
            {
                "type": "Only valid when `output_mode` is `\"tf_idf\"`. A tuple, list, 1D numpy array, or 1D tensor or the same length as the vocabulary, containing the floating point inverse document frequency weights, which will be multiplied by per sample term counts for the final `tf_idf` weight. If the `vocabulary` argument is set, and `output_mode` is `\"tf_idf\"`, this argument must be supplied",
                "name": "idf_weights",
                "doc": "Only valid when `output_mode` is `\"tf_idf\"`. A tuple, list, 1D numpy array, or 1D tensor or the same length as the vocabulary, containing the floating point inverse document frequency weights, which will be multiplied by per sample term counts for the final `tf_idf` weight. If the `vocabulary` argument is set, and `output_mode` is `\"tf_idf\"`, this argument must be supplied"
            },
            {
                "type": "Any",
                "name": "encoding",
                "doc": "Any"
            },
            {
                "type": "bool",
                "name": "invert",
                "doc": "Only valid when `output_mode` is `\"int\"`. If True, this layer will map indices to vocabulary items instead of mapping vocabulary items to indices. Default to False"
            },
            {
                "type": "Specification for the output of the layer. Defaults to `\"int\"` Values can be `\"int\"`, `\"one_hot\"`, `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"` configuring the layer as follows: - `\"int\"`: Return the raw integer indices of the input tokens. - `\"one_hot\"`: Encodes each individual element in the input into an array the same size as the vocabulary, containing a 1 at the element index. If the last dimension is size 1, will encode on that dimension. If the last dimension is not size 1, will append a new dimension for the encoded output. - `\"multi_hot\"`: Encodes each sample in the input into a single array the same size as the vocabulary, containing a 1 for each vocabulary term present in the sample. Treats the last dimension as the sample dimension, if input shape is (..., sample_length), output shape will be (..., num_tokens). - `\"count\"`: As `\"multi_hot\"`, but the int array contains a count of the number of times the token at that index appeared in the sample. - `\"tf_idf\"`: As `\"multi_hot\"`, but the TF-IDF algorithm is applied to find the value in each token slot For `\"int\"` output, any shape of input and output is supported. For all other output modes, currently only output up to rank 2 is supported",
                "name": "output_mode",
                "doc": "Specification for the output of the layer. Defaults to `\"int\"` Values can be `\"int\"`, `\"one_hot\"`, `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"` configuring the layer as follows: - `\"int\"`: Return the raw integer indices of the input tokens. - `\"one_hot\"`: Encodes each individual element in the input into an array the same size as the vocabulary, containing a 1 at the element index. If the last dimension is size 1, will encode on that dimension. If the last dimension is not size 1, will append a new dimension for the encoded output. - `\"multi_hot\"`: Encodes each sample in the input into a single array the same size as the vocabulary, containing a 1 for each vocabulary term present in the sample. Treats the last dimension as the sample dimension, if input shape is (..., sample_length), output shape will be (..., num_tokens). - `\"count\"`: As `\"multi_hot\"`, but the int array contains a count of the number of times the token at that index appeared in the sample. - `\"tf_idf\"`: As `\"multi_hot\"`, but the TF-IDF algorithm is applied to find the value in each token slot For `\"int\"` output, any shape of input and output is supported. For all other output modes, currently only output up to rank 2 is supported"
            },
            {
                "type": "bool",
                "name": "sparse",
                "doc": "Boolean. Only applicable when `output_mode` is `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"`. If True, returns a `SparseTensor` instead of a dense `Tensor`. Defaults to False"
            },
            {
                "type": "bool",
                "name": "pad_to_max_tokens",
                "doc": "Only applicable when `output_mode` is `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"`. If True, the output will have its feature axis padded to `max_tokens` even if the number of unique tokens in the vocabulary is less than max_tokens, resulting in a tensor of shape [batch_size, max_tokens] regardless of vocabulary size. Defaults to False"
            }
        ]
    },
    "Subtract": {
        "multipleInputs": false,
        "doc": "Layer that subtracts two inputs\n",
        "altersShape": true,
        "params": []
    },
    "TextVectorization": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "bool",
                "name": "max_tokens",
                "doc": "Maximum size of the vocabulary for this layer. This should only be specified when adapting a vocabulary or when setting `pad_to_max_tokens=True`. Note that this vocabulary contains 1 OOV token, so the effective number of tokens is `(max_tokens - 1 - (1 if output_mode == \"int\" else 0))`"
            },
            {
                "type": "Optional specification for standardization to apply to the input text. Values can be: - `None`: No standardization. - `\"lower_and_strip_punctuation\"`: Text will be lowercased and all punctuation removed. - `\"lower\"`: Text will be lowercased. - `\"strip_punctuation\"`: All punctuation will be removed. - Callable: Inputs will passed to the callable function, which should standardized and returned",
                "name": "standardize",
                "doc": "Optional specification for standardization to apply to the input text. Values can be: - `None`: No standardization. - `\"lower_and_strip_punctuation\"`: Text will be lowercased and all punctuation removed. - `\"lower\"`: Text will be lowercased. - `\"strip_punctuation\"`: All punctuation will be removed. - Callable: Inputs will passed to the callable function, which should standardized and returned"
            },
            {
                "type": "Optional specification for splitting the input text. Values can be: - `None`: No splitting. - `\"whitespace\"`: Split on whitespace. - `\"character\"`: Split on each unicode character. - Callable: Standardized inputs will passed to the callable function, which should split and returned",
                "name": "split",
                "doc": "Optional specification for splitting the input text. Values can be: - `None`: No splitting. - `\"whitespace\"`: Split on whitespace. - `\"character\"`: Split on each unicode character. - Callable: Standardized inputs will passed to the callable function, which should split and returned"
            },
            {
                "type": "Optional specification for ngrams to create from the possibly-split input text. Values can be None, an integer or tuple of integers; passing an integer will create ngrams up to that integer, and passing a tuple of integers will create ngrams for the specified values in the tuple. Passing None means that no ngrams will be created",
                "name": "ngrams",
                "doc": "Optional specification for ngrams to create from the possibly-split input text. Values can be None, an integer or tuple of integers; passing an integer will create ngrams up to that integer, and passing a tuple of integers will create ngrams for the specified values in the tuple. Passing None means that no ngrams will be created"
            },
            {
                "type": "Optional specification for the output of the layer. Values can be `\"int\"`, `\"multi_hot\"`, `\"count\"` or `\"tf_idf\"`, configuring the layer as follows: - `\"int\"`: Outputs integer indices, one integer index per split string token. When `output_mode == \"int\"`, 0 is reserved for masked locations; this reduces the vocab size to `max_tokens - 2` instead of `max_tokens - 1`. - `\"multi_hot\"`: Outputs a single int array per batch, of either vocab_size or max_tokens size, containing 1s in all elements where the token mapped to that index exists at least once in the batch item. - `\"count\"`: Like `\"multi_hot\"`, but the int array contains a count of the number of times the token at that index appeared in the batch item. - `\"tf_idf\"`: Like `\"multi_hot\"`, but the TF-IDF algorithm is applied to find the value in each token slot For `\"int\"` output, any shape of input and output is supported. For all other output modes, currently only rank 1 inputs (and rank 2 outputs after splitting) are supported",
                "name": "output_mode",
                "doc": "Optional specification for the output of the layer. Values can be `\"int\"`, `\"multi_hot\"`, `\"count\"` or `\"tf_idf\"`, configuring the layer as follows: - `\"int\"`: Outputs integer indices, one integer index per split string token. When `output_mode == \"int\"`, 0 is reserved for masked locations; this reduces the vocab size to `max_tokens - 2` instead of `max_tokens - 1`. - `\"multi_hot\"`: Outputs a single int array per batch, of either vocab_size or max_tokens size, containing 1s in all elements where the token mapped to that index exists at least once in the batch item. - `\"count\"`: Like `\"multi_hot\"`, but the int array contains a count of the number of times the token at that index appeared in the batch item. - `\"tf_idf\"`: Like `\"multi_hot\"`, but the TF-IDF algorithm is applied to find the value in each token slot For `\"int\"` output, any shape of input and output is supported. For all other output modes, currently only rank 1 inputs (and rank 2 outputs after splitting) are supported"
            },
            {
                "type": "Only valid in INT mode. If set, the output will have its time dimension padded or truncated to exactly `output_sequence_length` values, resulting in a tensor of shape `(batch_size, output_sequence_length)` regardless of how many tokens resulted from the splitting step. Defaults to None",
                "name": "output_sequence_length",
                "doc": "Only valid in INT mode. If set, the output will have its time dimension padded or truncated to exactly `output_sequence_length` values, resulting in a tensor of shape `(batch_size, output_sequence_length)` regardless of how many tokens resulted from the splitting step. Defaults to None"
            },
            {
                "type": "bool",
                "name": "pad_to_max_tokens",
                "doc": "Only valid in `\"multi_hot\"`, `\"count\"`, and `\"tf_idf\"` modes. If True, the output will have its feature axis padded to `max_tokens` even if the number of unique tokens in the vocabulary is less than max_tokens, resulting in a tensor of shape `(batch_size, max_tokens)` regardless of vocabulary size. Defaults to False"
            },
            {
                "type": "Optional. Either an array of strings or a string path to a text file. If passing an array, can pass a tuple, list, 1D numpy array, or 1D tensor containing the string vocbulary terms. If passing a file path, the file should contain one line per term in the vocabulary. If this argument is set, there is no need to `adapt()` the layer",
                "name": "vocabulary",
                "doc": "Optional. Either an array of strings or a string path to a text file. If passing an array, can pass a tuple, list, 1D numpy array, or 1D tensor containing the string vocbulary terms. If passing a file path, the file should contain one line per term in the vocabulary. If this argument is set, there is no need to `adapt()` the layer"
            },
            {
                "type": "Only valid when `output_mode` is `\"tf_idf\"`. A tuple, list, 1D numpy array, or 1D tensor or the same length as the vocabulary, containing the floating point inverse document frequency weights, which will be multiplied by per sample term counts for the final `tf_idf` weight. If the `vocabulary` argument is set, and `output_mode` is `\"tf_idf\"`, this argument must be supplied",
                "name": "idf_weights",
                "doc": "Only valid when `output_mode` is `\"tf_idf\"`. A tuple, list, 1D numpy array, or 1D tensor or the same length as the vocabulary, containing the floating point inverse document frequency weights, which will be multiplied by per sample term counts for the final `tf_idf` weight. If the `vocabulary` argument is set, and `output_mode` is `\"tf_idf\"`, this argument must be supplied"
            },
            {
                "type": "bool",
                "name": "sparse",
                "doc": "Boolean. Only applicable to `\"multi_hot\"`, `\"count\"`, and `\"tf_idf\"` output modes. If True, returns a `SparseTensor` instead of a dense `Tensor`. Defaults to False"
            },
            {
                "type": "bool",
                "name": "ragged",
                "doc": "Boolean. Only applicable to `\"int\"` output mode. If True, returns a `RaggedTensor` instead of a dense `Tensor`, where each sequence may have a different length after string splitting. Defaults to False"
            }
        ]
    },
    "ThresholdedReLU": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "float",
                "name": "theta",
                "doc": "Float >= 0. Threshold location of activation"
            }
        ]
    },
    "TimeDistributed": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "a `tf.keras.layers.Layer` instance",
                "name": "layer",
                "doc": "a `tf.keras.layers.Layer` instance"
            }
        ]
    },
    "UpSampling1D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "int",
                "name": "size",
                "doc": "Integer. Upsampling factor"
            }
        ]
    },
    "UpSampling2D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "tuple",
                "name": "size",
                "doc": "Int, or tuple of 2 integers The upsampling factors for rows and columns"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch_size, height, width, channels)` while `channels_first` corresponds to inputs with shape `(batch_size, channels, height, width)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "A string, one of `nearest` or `bilinear`",
                "name": "interpolation",
                "doc": "A string, one of `nearest` or `bilinear`"
            }
        ]
    },
    "UpSampling3D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "tuple",
                "name": "size",
                "doc": "Int, or tuple of 3 integers The upsampling factors for dim1, dim2 and dim3"
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)` while `channels_first` corresponds to inputs with shape `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            }
        ]
    },
    "Wrapper": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "The layer to be wrapped",
                "name": "layer",
                "doc": "The layer to be wrapped"
            }
        ]
    },
    "ZeroPadding1D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "tuple",
                "name": "padding",
                "doc": "Int, or tuple of int (length 2), or dictionary. - If int: How many zeros to add at the beginning and end of the padding dimension (axis 1). - If tuple of int (length 2): How many zeros to add at the beginning and the end of the padding dimension (`(left_pad, right_pad)`)"
            }
        ]
    },
    "ZeroPadding2D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "tuple",
                "name": "padding",
                "doc": "Int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints - If int: the same symmetric padding is applied to height and width - If tuple of 2 ints: interpreted as two different symmetric padding values for height and width: `(symmetric_height_pad, symmetric_width_pad)` - If tuple of 2 tuples of 2 ints: interpreted as `((top_pad, bottom_pad), (left_pad, right_pad))` data_format: A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch_size, height, width, channels)` while `channels_first` corresponds to inputs with shape `(batch_size, channels, height, width)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "Any"
            }
        ]
    },
    "ZeroPadding3D": {
        "multipleInputs": false,
        "doc": "",
        "altersShape": true,
        "params": [
            {
                "type": "tuple",
                "name": "padding",
                "doc": "Int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints - If int: the same symmetric padding is applied to height and width - If tuple of 3 ints: interpreted as two different symmetric padding values for height and width: `(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad)` - If tuple of 3 tuples of 2 ints: interpreted as `((left_dim1_pad, right_dim1_pad), (left_dim2_pad, right_dim2_pad), (left_dim3_pad, right_dim3_pad))` data_format: A string, one of `channels_last` (default) or `channels_first` The ordering of the dimensions in the inputs `channels_last` corresponds to inputs with shape `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)` while `channels_first` corresponds to inputs with shape `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)` It defaults to the `image_data_format` value found in your Keras config file at `~/.keras/keras.json` If you never set it, then it will be \"channels_last\""
            },
            {
                "type": "string",
                "name": "data_format",
                "doc": "Any"
            }
        ]
    },
    "experimental": {
        "multipleInputs": false,
        "doc": "Public API for tf.keras.layers.experimental namespace\n",
        "altersShape": true,
        "params": []
    }
}